<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>HBase协处理器错误记录</title>
      <link href="/2020/06/18/hbase/HBase%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8%E9%94%99%E8%AF%AF%E8%AE%B0%E5%BD%95/"/>
      <url>/2020/06/18/hbase/HBase%E5%8D%8F%E5%A4%84%E7%90%86%E5%99%A8%E9%94%99%E8%AF%AF%E8%AE%B0%E5%BD%95/</url>
      
        <content type="html"><![CDATA[<h2 id="2-Hbase2-0-协处理器失效问题"><a href="#2-Hbase2-0-协处理器失效问题" class="headerlink" title="2.Hbase2.0+协处理器失效问题"></a>2.Hbase2.0+协处理器失效问题</h2><p>再Hbase2.0+协处理器没用</p><h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>Hbase2.0+移除了继承BaseRegionObserver，改为实现 RegionObserver, RegionCoprocessor<br>并要添加方法</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> Optional&lt;RegionObserver&gt; <span class="title">getRegionObserver</span><span class="params">()</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> Optional.of(<span class="keyword">this</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-在将HBase添加协处理器时，出现错误"><a href="#2-在将HBase添加协处理器时，出现错误" class="headerlink" title="2.在将HBase添加协处理器时，出现错误"></a>2.在将HBase添加协处理器时，出现错误</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ERROR: org.apache.hadoop.hbase.DoNotRetryIOException: Class cn.bryce.textstuCoprocessor cannot be loaded Set hbase.table.sanity.checks to false at conf or table descriptor if you want to bypass sanity checks</span><br><span class="line">    at org.apache.hadoop.hbase.master.HMaster.warnOrThrowExceptionForFailure(HMaster.java:1707)</span><br><span class="line">    at org.apache.hadoop.hbase.master.HMaster.sanityCheckTableDescriptor(HMaster.java:1568)</span><br><span class="line">    at org.apache.hadoop.hbase.master.HMaster.modifyTable(HMaster.java:2055)</span><br><span class="line">    at org.apache.hadoop.hbase.master.MasterRpcServices.modifyTable(MasterRpcServices.java:1176)</span><br><span class="line">    at org.apache.hadoop.hbase.protobuf.generated.MasterProtos$MasterService$2.callBlockingMethod(MasterProtos.java:55680)</span><br><span class="line">    at org.apache.hadoop.hbase.ipc.RpcServer.call(RpcServer.java:2170)</span><br><span class="line">    at org.apache.hadoop.hbase.ipc.CallRunner.run(CallRunner.java:109)</span><br><span class="line">    at org.apache.hadoop.hbase.ipc.RpcExecutor.consumerLoop(RpcExecutor.java:133)</span><br><span class="line">    at org.apache.hadoop.hbase.ipc.RpcExecutor$1.run(RpcExecutor.java:108)</span><br><span class="line">    at java.lang.Thread.run(Thread.java:748)</span><br></pre></td></tr></table></figure><h3 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h3><p><strong>重点</strong>1.首先检查协处理器代码是否写正确<br>2.再hdfs-site.xml添加配置信息</p><figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.table.sanity.checks<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure><p>注意：若是协处理器代码的问题，将会导致下面的问题。</p><h2 id="3-HBase找不到协处理器导致RegionServer全部挂掉"><a href="#3-HBase找不到协处理器导致RegionServer全部挂掉" class="headerlink" title="3.HBase找不到协处理器导致RegionServer全部挂掉"></a>3.HBase找不到协处理器导致RegionServer全部挂掉</h2><h2 id="解决方案-1"><a href="#解决方案-1" class="headerlink" title="解决方案"></a>解决方案</h2><ol><li>修改HBase的默认配置<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!--该配置会禁用协处理器 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>hbase.coprocessor.abortonerror<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>false<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure></li><li>找到出现问题的带有协处理器的表，del掉</li></ol>]]></content>
      
      
      <categories>
          
          <category> Hbase </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Hbase </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hashmap扩容机制</title>
      <link href="/2020/06/14/java/hash/Hashmap%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/"/>
      <url>/2020/06/14/java/hash/Hashmap%E6%89%A9%E5%AE%B9%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h1 id="HashMap-扩容机制"><a href="#HashMap-扩容机制" class="headerlink" title="HashMap 扩容机制"></a>HashMap 扩容机制</h1><p>首先hashmap中有一个重要的参数</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment">     * The number of key-value mappings contained in this map.</span></span><br><span class="line"><span class="comment">     */</span>    </span><br><span class="line">   <span class="keyword">transient</span> <span class="keyword">int</span> size;</span><br></pre></td></tr></table></figure><p>这个数值记录了当前的数据量，当数据量达到阈值，就会触发扩容机制。</p><p><strong>扩容算法</strong>：</p><h2 id="扩容长度"><a href="#扩容长度" class="headerlink" title="扩容长度"></a>扩容长度</h2><p>在hashmap中，table数组的长度必须是2^n数。所以，扩容的长度是根据上一次的table长度经过位移运算获取。<br>假设当前的tableSize的长度为16.那么扩容后的长度为16&lt;&lt;1 == 32。<br>之所以不采用乘数运算，也是因为性能原因。在底层，cpu不支持乘法运算，所以最终还是会转化为加法运算。但是采用位运算，效率会大大提高。</p><h2 id="hashmap扩容为什么是2倍，而不是1-5倍？"><a href="#hashmap扩容为什么是2倍，而不是1-5倍？" class="headerlink" title="hashmap扩容为什么是2倍，而不是1.5倍？"></a>hashmap扩容为什么是2倍，而不是1.5倍？</h2><p>首先hashmap通过indexFor来计算出当前数值应该放置于数值的哪一个位置。<br>这个运算方法是<strong>h &amp; (length-1)</strong>。<br>第一个数值是当前数的hash值。<br>假设数值为 01010101 &amp; 00001111 == 00000101<br>所以这个计算出来的结果5.放置与第5个格子<br>对于这个位运算，不管怎么计算，其结果只能在[0,15]之间。</p><p>了解了数值的放置规则，我们在来看看hashmap中数值的长度为什么一定要是2^n。<br>首先假设数组长度为5。来看看经过运算，数据会出现什么样的分布。<br>5-1==4转化为二进制位=&gt; 00000100  可以看到高4位都是0，低4位只有第三位是1.按照位运算&amp;的规则 只有第三位能得到0或者1.其余的位数只能是0.<br>所以，如果数组长度为5，数组经过计算，只能放置在索引为0或者4的位置上。这就造成了严重的资源浪费。<br>所以，为了不造成资源浪费。数组必须保证低4位都是1才能保证数据能分布在数组的每个索引位上。</p><h2 id="hashmap的冷知识：Hashmap-JDK1-8-在极限情况下，单个索引位能放置多少个元素才会变成红黑树"><a href="#hashmap的冷知识：Hashmap-JDK1-8-在极限情况下，单个索引位能放置多少个元素才会变成红黑树" class="headerlink" title="hashmap的冷知识：Hashmap(JDK1.8)在极限情况下，单个索引位能放置多少个元素才会变成红黑树"></a>hashmap的冷知识：Hashmap(JDK1.8)在极限情况下，单个索引位能放置多少个元素才会变成红黑树</h2><p>一般我们认为，链表长度大于8，数组长度大于64就会转化为红黑树。<br>所以，在极限情况下，假设所有的数据都放置在同一个索引上。<br>对于数据同一个索引：<br>在数据量达到9时，数组会发送第一次扩容16 &gt;&gt; 32<br>在数据量达到10时，数组发送第二次扩容32 &gt;&gt; 64<br>在数据量达到11时，数组就不会发送扩容，而是转化为红黑树。<br><strong>在极限情况下，hashmap在极限情况下，单个索引位能放置11个元素才会变成红黑树</strong></p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
          <category> hashmap </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 源码 </tag>
            
            <tag> hashmap </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hashmap源码解析</title>
      <link href="/2020/06/04/java/hash/Hashmap%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"/>
      <url>/2020/06/04/java/hash/Hashmap%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h1 id="HashMap-源码剖析"><a href="#HashMap-源码剖析" class="headerlink" title="HashMap 源码剖析"></a>HashMap 源码剖析</h1><ul><li><strong><em>如果你是要面对面试，可以直接去看下基本概念与总结</em></strong></li></ul><h2 id="1-hashmap的基本概念"><a href="#1-hashmap的基本概念" class="headerlink" title="1.hashmap的基本概念"></a>1.hashmap的基本概念</h2><ul><li>hash的基本概念：把一个任意长度的基本输入，通过一系列的hash算法映射成一个固定长度的输出。有时候两个不同的输入，映射出一个相同的输出，这种情况呗称为hash冲突。</li><li>hashmap的存储结构按JDK8来说是：数组+链表+红黑树构成的。<br><img src="https://s1.ax1x.com/2020/06/04/twI1bR.png" alt="twI1bR.png"></li><li>hashmap的每一个存储单元称为一个node结构。node中包含了：<br>key字段：map中key的字段<br>value字段：map中value的字段<br>next字段：当发生hash冲突的时候，当前桶中的node与发生冲突的node形成编标要用到的字段<br>hash字段：存储key的hash值，但是要经过一次扰动</li></ul><h2 id="2-hashmap类"><a href="#2-hashmap类" class="headerlink" title="2.hashmap类"></a>2.hashmap类</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HashMap</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">AbstractMap</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt;</span></span><br><span class="line"><span class="class">    <span class="keyword">implements</span> <span class="title">Map</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt;, <span class="title">Cloneable</span>, <span class="title">Serializable</span> </span>&#123;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="3-hashmap基本属性"><a href="#3-hashmap基本属性" class="headerlink" title="3.hashmap基本属性"></a>3.hashmap基本属性</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">long</span> serialVersionUID = <span class="number">362498820763181265L</span>;<span class="comment">//序列化版本号</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> DEFAULT_INITIAL_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">4</span>; <span class="comment">// 初始化长度为16，切必须是2的N次方</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MAXIMUM_CAPACITY = <span class="number">1</span> &lt;&lt; <span class="number">30</span>;<span class="comment">//最大的容量为2^30，一般用于自定义初始化容量</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">float</span> DEFAULT_LOAD_FACTOR = <span class="number">0.75f</span>;<span class="comment">//默认负载因子</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> TREEIFY_THRESHOLD = <span class="number">8</span>;<span class="comment">//数组单个单元要转化为红黑树节点的阈值</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> UNTREEIFY_THRESHOLD = <span class="number">6</span>;<span class="comment">//反树化时，节点的阈值</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> MIN_TREEIFY_CAPACITY = <span class="number">64</span>;<span class="comment">//树化时数组长度的阈值</span></span><br></pre></td></tr></table></figure><h2 id="4-hashmap-Node属性"><a href="#4-hashmap-Node属性" class="headerlink" title="4.hashmap Node属性"></a>4.hashmap Node属性</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//hashmap中节点的基本属性，实现get，set方法。重写了hashCode、toString、equals方法。 属性在上文有介绍</span></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Node</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">implements</span> <span class="title">Map</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">        <span class="keyword">final</span> <span class="keyword">int</span> hash;</span><br><span class="line">        <span class="keyword">final</span> K key;</span><br><span class="line">        V value;</span><br><span class="line">        Node&lt;K,V&gt; next;</span><br><span class="line"></span><br><span class="line">        Node(<span class="keyword">int</span> hash, K key, V value, Node&lt;K,V&gt; next) &#123;</span><br><span class="line">            <span class="keyword">this</span>.hash = hash;</span><br><span class="line">            <span class="keyword">this</span>.key = key;</span><br><span class="line">            <span class="keyword">this</span>.value = value;</span><br><span class="line">            <span class="keyword">this</span>.next = next;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> K <span class="title">getKey</span><span class="params">()</span>        </span>&#123; <span class="keyword">return</span> key; &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> V <span class="title">getValue</span><span class="params">()</span>      </span>&#123; <span class="keyword">return</span> value; &#125;</span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> String <span class="title">toString</span><span class="params">()</span> </span>&#123; <span class="keyword">return</span> key + <span class="string">"="</span> + value; &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">hashCode</span><span class="params">()</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> Objects.hashCode(key) ^ Objects.hashCode(value);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> V <span class="title">setValue</span><span class="params">(V newValue)</span> </span>&#123;</span><br><span class="line">            V oldValue = value;</span><br><span class="line">            value = newValue;</span><br><span class="line">            <span class="keyword">return</span> oldValue;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">boolean</span> <span class="title">equals</span><span class="params">(Object o)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">if</span> (o == <span class="keyword">this</span>)</span><br><span class="line">                <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            <span class="keyword">if</span> (o <span class="keyword">instanceof</span> Map.Entry) &#123;</span><br><span class="line">                Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o;</span><br><span class="line">                <span class="keyword">if</span> (Objects.equals(key, e.getKey()) &amp;&amp;</span><br><span class="line">                    Objects.equals(value, e.getValue()))</span><br><span class="line">                    <span class="keyword">return</span> <span class="keyword">true</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">return</span> <span class="keyword">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//扰动函数，用于计算hash值，在之后专门专题讲解。</span></span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">hash</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> h;</span><br><span class="line">        <span class="keyword">return</span> (key == <span class="keyword">null</span>) ? <span class="number">0</span> : (h = key.hashCode()) ^ (h &gt;&gt;&gt; <span class="number">16</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//在发送hash冲突的时候。用于比较两个node。</span></span><br><span class="line">    <span class="keyword">static</span> Class&lt;?&gt; comparableClassFor(Object x) &#123;</span><br><span class="line">        <span class="keyword">if</span> (x <span class="keyword">instanceof</span> Comparable) &#123;</span><br><span class="line">            Class&lt;?&gt; c; Type[] ts, as; Type t; ParameterizedType p;</span><br><span class="line">            <span class="keyword">if</span> ((c = x.getClass()) == String<span class="class">.<span class="keyword">class</span>) // <span class="title">bypass</span> <span class="title">checks</span></span></span><br><span class="line"><span class="class">                <span class="title">return</span> <span class="title">c</span></span>;</span><br><span class="line">            <span class="keyword">if</span> ((ts = c.getGenericInterfaces()) != <span class="keyword">null</span>) &#123;</span><br><span class="line">                <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; ts.length; ++i) &#123;</span><br><span class="line">                    <span class="keyword">if</span> (((t = ts[i]) <span class="keyword">instanceof</span> ParameterizedType) &amp;&amp;</span><br><span class="line">                        ((p = (ParameterizedType)t).getRawType() ==</span><br><span class="line">                         Comparable<span class="class">.<span class="keyword">class</span>) &amp;&amp;</span></span><br><span class="line"><span class="class">                        (<span class="title">as</span> </span>= p.getActualTypeArguments()) != <span class="keyword">null</span> &amp;&amp;</span><br><span class="line">                        as.length == <span class="number">1</span> &amp;&amp; as[<span class="number">0</span>] == c) <span class="comment">// type arg is c</span></span><br><span class="line">                        <span class="keyword">return</span> c;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">compareComparables</span><span class="params">(Class&lt;?&gt; kc, Object k, Object x)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (x == <span class="keyword">null</span> || x.getClass() != kc ? <span class="number">0</span> :</span><br><span class="line">                ((Comparable)k).compareTo(x));</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h2 id="5-hashmap-构造器原理与字段"><a href="#5-hashmap-构造器原理与字段" class="headerlink" title="5.hashmap 构造器原理与字段"></a>5.hashmap 构造器原理与字段</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line">    <span class="comment">//用于寻找大于或等于capacity的最小2的幂</span></span><br><span class="line">    <span class="function"><span class="keyword">static</span> <span class="keyword">final</span> <span class="keyword">int</span> <span class="title">tableSizeFor</span><span class="params">(<span class="keyword">int</span> cap)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">int</span> n = cap - <span class="number">1</span>;</span><br><span class="line">        n |= n &gt;&gt;&gt; <span class="number">1</span>;</span><br><span class="line">        n |= n &gt;&gt;&gt; <span class="number">2</span>;</span><br><span class="line">        n |= n &gt;&gt;&gt; <span class="number">4</span>;</span><br><span class="line">        n |= n &gt;&gt;&gt; <span class="number">8</span>;</span><br><span class="line">        n |= n &gt;&gt;&gt; <span class="number">16</span>;</span><br><span class="line">        <span class="keyword">return</span> (n &lt; <span class="number">0</span>) ? <span class="number">1</span> : (n &gt;= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + <span class="number">1</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="comment">//字段</span></span><br><span class="line"><span class="keyword">transient</span> Node&lt;K,V&gt;[] table; <span class="comment">//hashMap数组的表示</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">transient</span> Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet; <span class="comment">//entry节点</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> size; <span class="comment">//数组长度</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">transient</span> <span class="keyword">int</span> modCount; <span class="comment">//添加的元素个数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span> threshold; <span class="comment">//合理的初始化数组长度，根据tableSizeFor()得到，用于手动设置时使用</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">final</span> <span class="keyword">float</span> loadFactor; <span class="comment">//负载因子，用于手动设置时使用</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//构造器</span></span><br><span class="line"><span class="comment">//构造器一：定义Node[]数组初始长度，与负载因子</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity, <span class="keyword">float</span> loadFactor)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">if</span> (initialCapacity &lt; <span class="number">0</span>)</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal initial capacity: "</span> +</span><br><span class="line">                                               initialCapacity);</span><br><span class="line">        <span class="keyword">if</span> (initialCapacity &gt; MAXIMUM_CAPACITY)</span><br><span class="line">            initialCapacity = MAXIMUM_CAPACITY;</span><br><span class="line">        <span class="keyword">if</span> (loadFactor &lt;= <span class="number">0</span> || Float.isNaN(loadFactor))</span><br><span class="line">            <span class="keyword">throw</span> <span class="keyword">new</span> IllegalArgumentException(<span class="string">"Illegal load factor: "</span> +</span><br><span class="line">                                               loadFactor);</span><br><span class="line">        <span class="comment">//手动设定负载因子</span></span><br><span class="line">        <span class="keyword">this</span>.loadFactor = loadFactor;</span><br><span class="line">        <span class="comment">//自动设置合适的数组长度</span></span><br><span class="line">        <span class="keyword">this</span>.threshold = tableSizeFor(initialCapacity);</span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="comment">//构造器二：定义Node[]数组初始长度，默认负载因子</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(<span class="keyword">int</span> initialCapacity)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>(initialCapacity, DEFAULT_LOAD_FACTOR);</span><br><span class="line">    &#125;</span><br><span class="line"><span class="comment">//构造器三：仅创建HashMap对象，并初始化负债因子为0.75f</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.loadFactor = DEFAULT_LOAD_FACTOR; <span class="comment">// all other fields defaulted</span></span><br><span class="line">    &#125;</span><br><span class="line">    </span><br><span class="line"><span class="comment">//构造器四：转化hashmap的父类</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">HashMap</span><span class="params">(Map&lt;? extends K, ? extends V&gt; m)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">this</span>.loadFactor = DEFAULT_LOAD_FACTOR;</span><br><span class="line">        <span class="comment">//这个方法为，将map中所有数据插入到hashmap中，此文不再描述</span></span><br><span class="line">        putMapEntries(m, <span class="keyword">false</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h2 id="6-hashmap树节点-简要分析"><a href="#6-hashmap树节点-简要分析" class="headerlink" title="6.hashmap树节点(简要分析)"></a>6.hashmap树节点(简要分析)</h2><p>hashmap树节点比较复杂，之后做专门的分析</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">TreeNode</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; <span class="keyword">extends</span> <span class="title">LinkedHashMap</span>.<span class="title">Entry</span>&lt;<span class="title">K</span>,<span class="title">V</span>&gt; </span>&#123;</span><br><span class="line">        TreeNode&lt;K,V&gt; parent;  <span class="comment">// 父节点</span></span><br><span class="line">        TreeNode&lt;K,V&gt; left;<span class="comment">//左节点</span></span><br><span class="line">        TreeNode&lt;K,V&gt; right;<span class="comment">//右节点</span></span><br><span class="line">        TreeNode&lt;K,V&gt; prev;    <span class="comment">// 记录上一个节点</span></span><br><span class="line">        <span class="keyword">boolean</span> red;<span class="comment">//节点红黑判断</span></span><br><span class="line">        TreeNode(<span class="keyword">int</span> hash, K key, V val, Node&lt;K,V&gt; next) &#123;</span><br><span class="line">            <span class="keyword">super</span>(hash, key, val, next);</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><h2 id="7-hashmap-get方法"><a href="#7-hashmap-get方法" class="headerlink" title="7.hashmap get方法"></a>7.hashmap get方法</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//调用的GET方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">get</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt; e;</span><br><span class="line">    <span class="keyword">return</span> (e = getNode(hash(key), key)) == <span class="keyword">null</span> ? <span class="keyword">null</span> : e.value;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//实际执行的GET方法</span></span><br><span class="line"><span class="function"><span class="keyword">final</span> Node&lt;K,V&gt; <span class="title">getNode</span><span class="params">(<span class="keyword">int</span> hash, Object key)</span> </span>&#123;</span><br><span class="line">Node&lt;K,V&gt;[] tab; </span><br><span class="line">    Node&lt;K,V&gt; first, e; </span><br><span class="line">    <span class="keyword">int</span> n; K k;</span><br><span class="line">    <span class="comment">// table不为空 &amp;&amp; table长度大于0 &amp;&amp; table索引位置(根据hash值计算出)节点不为空</span></span><br><span class="line">    <span class="keyword">if</span> ((tab = table) != <span class="keyword">null</span> &amp;&amp; (n = tab.length) &gt; <span class="number">0</span> &amp;&amp; (first = tab[(n - <span class="number">1</span>) &amp; hash]) != <span class="keyword">null</span>) &#123;</span><br><span class="line">        <span class="comment">// first的key等于传入的key则返回first对象</span></span><br><span class="line">        <span class="keyword">if</span> (first.hash == hash &amp;&amp; ((k = first.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">            <span class="keyword">return</span> first;</span><br><span class="line">        <span class="comment">//first的key不等于传入的key则说明是链表，向下遍历</span></span><br><span class="line">        <span class="keyword">if</span> ((e = first.next) != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 判断是否为TreeNode，是则为红黑树</span></span><br><span class="line">            <span class="comment">// 如果是红黑树节点，则调用红黑树的查找目标节点方法getTreeNode</span></span><br><span class="line">            <span class="keyword">if</span> (first <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">                <span class="keyword">return</span> ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key);</span><br><span class="line">            <span class="comment">//走下列步骤表示是链表，循环至节点的key与传入的key值相等</span></span><br><span class="line">            <span class="keyword">do</span> &#123;</span><br><span class="line">                <span class="keyword">if</span> (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">                    <span class="keyword">return</span> e;</span><br><span class="line">            &#125; <span class="keyword">while</span> ((e = e.next) != <span class="keyword">null</span>);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//找不到符合的返回空</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="7-hashmap-put方法"><a href="#7-hashmap-put方法" class="headerlink" title="7.hashmap put方法"></a>7.hashmap put方法</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="comment">//掉用的PUT方法，hash(key)调用本例中的hash()方法</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">put</span><span class="params">(K key, V value)</span> </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> putVal(hash(key), key, value, <span class="keyword">false</span>, <span class="keyword">true</span>);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 实际执行的PUT方法 </span></span><br><span class="line"><span class="comment"> * Implements Map.put and related methods</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> hash hash for key</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> key the key</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> value the value to put</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> onlyIfAbsent if true, don't change existing value</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> evict if false, the table is in creation mode.</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span> previous value, or null if none</span></span><br><span class="line"><span class="comment"> */</span> </span><br><span class="line"><span class="function"><span class="keyword">final</span> V <span class="title">putVal</span><span class="params">(<span class="keyword">int</span> hash, K key, V value, <span class="keyword">boolean</span> onlyIfAbsent, <span class="keyword">boolean</span> evict)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt;[] tab;</span><br><span class="line">    Node&lt;K,V&gt; p;</span><br><span class="line">    <span class="keyword">int</span> n, i;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// table是否为空或者length等于0, 如果是则调用resize方法进行初始化</span></span><br><span class="line">    <span class="comment">// table是一个 （Node&lt;K,V&gt;[] table;） Node类型的数组</span></span><br><span class="line">    <span class="keyword">if</span> ((tab = table) == <span class="keyword">null</span> || (n = tab.length) == <span class="number">0</span>)</span><br><span class="line">        n = (tab = resize()).length;</span><br><span class="line">        </span><br><span class="line">    <span class="comment">// 通过hash值计算索引位置, 如果table表该索引位置节点为空则新增一个</span></span><br><span class="line">    <span class="keyword">if</span> ((p = tab[i = (n - <span class="number">1</span>) &amp; hash]) == <span class="keyword">null</span>) <span class="comment">// 将索引位置的头节点赋值给p</span></span><br><span class="line">        tab[i] = newNode(hash, key, value, <span class="keyword">null</span>);</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">else</span> &#123; <span class="comment">// table表该索引位置不为空</span></span><br><span class="line">        Node&lt;K,V&gt; e; K k;</span><br><span class="line">        <span class="comment">//判断p节点的hash值和key值是否跟传入的hash值和key值相等</span></span><br><span class="line">        <span class="keyword">if</span> (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">            e = p; <span class="comment">// 如果相等, 则p节点即为要查找的目标节点，赋值给e</span></span><br><span class="line">        <span class="comment">// 判断p节点是否为TreeNode, 如果是则调用红黑树的putTreeVal方法查找目标节点</span></span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (p <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">            e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(<span class="keyword">this</span>, tab, hash, key, value);</span><br><span class="line">        <span class="comment">// 走到这代表p节点为普通链表节点</span></span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 遍历此链表, binCount用于统计节点数</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> binCount = <span class="number">0</span>; ; ++binCount) &#123;</span><br><span class="line">                <span class="comment">//p.next为空代表目标节点不存在</span></span><br><span class="line">                <span class="keyword">if</span> ((e = p.next) == <span class="keyword">null</span>) &#123;</span><br><span class="line">                    <span class="comment">//新增一个节点插入链表尾部</span></span><br><span class="line">                    p.next = newNode(hash, key, value, <span class="keyword">null</span>);</span><br><span class="line">                    <span class="comment">//如果节点数目超过8个，调用treeifyBin方法将该链表转换为红黑树</span></span><br><span class="line">                    <span class="keyword">if</span> (binCount &gt;= TREEIFY_THRESHOLD - <span class="number">1</span>) <span class="comment">// -1 for 1st</span></span><br><span class="line">                        treeifyBin(tab, hash);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">//e节点的hash值和key值都与传入的相等, 则e即为目标节点,跳出循环</span></span><br><span class="line">                <span class="keyword">if</span> (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                p = e;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// e不为空则代表根据传入的hash值和key值查找到了节点,将该节点的value覆盖,返回oldValue</span></span><br><span class="line">        <span class="keyword">if</span> (e != <span class="keyword">null</span>) &#123; <span class="comment">// existing mapping for key</span></span><br><span class="line">            V oldValue = e.value;</span><br><span class="line">            <span class="keyword">if</span> (!onlyIfAbsent || oldValue == <span class="keyword">null</span>)</span><br><span class="line">                e.value = value;</span><br><span class="line">            afterNodeAccess(e); <span class="comment">// 用于LinkedHashMap</span></span><br><span class="line">            <span class="keyword">return</span> oldValue;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">//map修改次数加1</span></span><br><span class="line">    ++modCount;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">//map节点数加1，如果超过阀值，则扩容</span></span><br><span class="line">    <span class="keyword">if</span> (++size &gt; threshold)</span><br><span class="line">        resize();</span><br><span class="line">    afterNodeInsertion(evict); <span class="comment">// 用于LinkedHashMap</span></span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="8-hashmap-resize-方法"><a href="#8-hashmap-resize-方法" class="headerlink" title="8.hashmap resize()方法"></a>8.hashmap resize()方法</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> Node&lt;K,V&gt;[] resize() &#123;</span><br><span class="line">        <span class="comment">//oldTab保存未扩容的tab</span></span><br><span class="line">        Node&lt;K,V&gt;[] oldTab = table;</span><br><span class="line">        <span class="comment">//oldTab最大容量</span></span><br><span class="line">        <span class="keyword">int</span> oldCap = (oldTab == <span class="keyword">null</span>) ? <span class="number">0</span> : oldTab.length;</span><br><span class="line">        <span class="comment">//oldTab阀值</span></span><br><span class="line">        <span class="keyword">int</span> oldThr = threshold;</span><br><span class="line">        <span class="keyword">int</span> newCap, newThr = <span class="number">0</span>;</span><br><span class="line">        <span class="comment">//如果老map有值</span></span><br><span class="line">        <span class="keyword">if</span> (oldCap &gt; <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="comment">// 老table的容量超过最大容量值，设置阈值为Integer.MAX_VALUE，返回老表</span></span><br><span class="line">            <span class="keyword">if</span> (oldCap &gt;= MAXIMUM_CAPACITY) &#123;</span><br><span class="line">                threshold = Integer.MAX_VALUE;</span><br><span class="line">                <span class="keyword">return</span> oldTab;</span><br><span class="line">            <span class="comment">//老table的容量没有超过最大容量值，将新容量赋值为老容量*2，如果新容量&lt;最大容量并且老容量&gt;=16, 则将新阈值设置为原来的两倍</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> ((newCap = oldCap &lt;&lt; <span class="number">1</span>) &lt; MAXIMUM_CAPACITY &amp;&amp;</span><br><span class="line">                    oldCap &gt;= DEFAULT_INITIAL_CAPACITY)</span><br><span class="line">                newThr = oldThr &lt;&lt; <span class="number">1</span>; <span class="comment">// double threshold</span></span><br><span class="line">        &#125;<span class="keyword">else</span> <span class="keyword">if</span> (oldThr &gt; <span class="number">0</span>)&#123; <span class="comment">// 老表的容量为0, 老表的阈值大于0, 是因为初始容量被放入阈值</span></span><br><span class="line">            newCap = oldThr;    <span class="comment">// 则将新表的容量设置为老表的阈值</span></span><br><span class="line">        <span class="comment">//放第一个值时，对数组容量及阈值进行初始化。</span></span><br><span class="line">        &#125;<span class="keyword">else</span> &#123;   <span class="comment">//老表的容量为0, 老表的阈值为0, 则为空表，设置默认容量和阈值</span></span><br><span class="line">            newCap = DEFAULT_INITIAL_CAPACITY; <span class="comment">//16</span></span><br><span class="line">            newThr = (<span class="keyword">int</span>)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); <span class="comment">//12</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 如果新阈值为空, 则通过新的容量*负载因子获得新阈值</span></span><br><span class="line">        <span class="keyword">if</span> (newThr == <span class="number">0</span>) &#123;</span><br><span class="line">            <span class="keyword">float</span> ft = (<span class="keyword">float</span>)newCap * loadFactor;</span><br><span class="line">            newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (<span class="keyword">float</span>)MAXIMUM_CAPACITY ? (<span class="keyword">int</span>)ft : Integer.MAX_VALUE);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 将当前阈值赋值为刚计算出来的新的阈值</span></span><br><span class="line">        threshold = newThr;</span><br><span class="line">        <span class="meta">@SuppressWarnings</span>(&#123;<span class="string">"rawtypes"</span>,<span class="string">"unchecked"</span>&#125;)</span><br><span class="line">        <span class="comment">//初始化数组对象</span></span><br><span class="line">        Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])<span class="keyword">new</span> Node[newCap];</span><br><span class="line">        <span class="comment">//将当前的表赋值为新定义的表</span></span><br><span class="line">        table = newTab;  </span><br><span class="line">        <span class="comment">// 如果老表不为空, 则需遍历将节点赋值给新表</span></span><br><span class="line">        <span class="keyword">if</span> (oldTab != <span class="keyword">null</span>) &#123;</span><br><span class="line">            <span class="comment">//通过循环将老数组重新赋值给新数组</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; oldCap; ++j) &#123;</span><br><span class="line">                Node&lt;K,V&gt; e;</span><br><span class="line">                <span class="keyword">if</span> ((e = oldTab[j]) != <span class="keyword">null</span>) &#123; <span class="comment">// 将索引值为j的老表头节点赋值给e</span></span><br><span class="line">                    oldTab[j] = <span class="keyword">null</span>; <span class="comment">//将老表的节点设置为空, 以便垃圾收集器回收空间</span></span><br><span class="line">                    <span class="comment">// 如果e.next为空, 则代表老表的该位置只有1个节点,</span></span><br><span class="line">                    <span class="comment">// 通过hash值计算新表的索引位置, 直接将该节点放在该位置</span></span><br><span class="line">                    <span class="keyword">if</span> (e.next == <span class="keyword">null</span>) <span class="comment">//</span></span><br><span class="line">                        newTab[e.hash &amp; (newCap - <span class="number">1</span>)] = e;</span><br><span class="line">                    <span class="comment">//e.next不为空,判断是否是红黑树</span></span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span> (e <span class="keyword">instanceof</span> TreeNode)</span><br><span class="line">                        ((TreeNode&lt;K,V&gt;)e).split(<span class="keyword">this</span>, newTab, j, oldCap);</span><br><span class="line">                    <span class="comment">//是普通链表</span></span><br><span class="line">                    <span class="keyword">else</span> &#123; <span class="comment">// preserve order</span></span><br><span class="line">                        Node&lt;K,V&gt; loHead = <span class="keyword">null</span>, loTail = <span class="keyword">null</span>;</span><br><span class="line">                        Node&lt;K,V&gt; hiHead = <span class="keyword">null</span>, hiTail = <span class="keyword">null</span>;</span><br><span class="line">                        Node&lt;K,V&gt; next;</span><br><span class="line">                        <span class="keyword">do</span> &#123;</span><br><span class="line">                            next = e.next;</span><br><span class="line">                            <span class="comment">//如果e的hash值与老表的容量进行与运算为0,则扩容后的索引位置跟老表的索引位置一样</span></span><br><span class="line">                            <span class="keyword">if</span> ((e.hash &amp; oldCap) == <span class="number">0</span>) &#123;</span><br><span class="line">                                <span class="keyword">if</span> (loTail == <span class="keyword">null</span>)</span><br><span class="line">                                    loHead = e;</span><br><span class="line">                                <span class="keyword">else</span></span><br><span class="line">                                    loTail.next = e;</span><br><span class="line">                                loTail = e;</span><br><span class="line">                            &#125;</span><br><span class="line">                            <span class="comment">//如果e的hash值与老表的容量进行与运算为1,则扩容后的索引位置为:</span></span><br><span class="line">                            <span class="comment">//老表的索引位置＋oldCap</span></span><br><span class="line">                            <span class="keyword">else</span> &#123;</span><br><span class="line">                                <span class="keyword">if</span> (hiTail == <span class="keyword">null</span>)</span><br><span class="line">                                    hiHead = e;</span><br><span class="line">                                <span class="keyword">else</span></span><br><span class="line">                                    hiTail.next = e;</span><br><span class="line">                                hiTail = e;</span><br><span class="line">                            &#125;</span><br><span class="line">                        &#125; <span class="keyword">while</span> ((e = next) != <span class="keyword">null</span>);</span><br><span class="line">                        <span class="keyword">if</span> (loTail != <span class="keyword">null</span>) &#123;</span><br><span class="line">                            loTail.next = <span class="keyword">null</span>; <span class="comment">// 最后一个节点的next设为空</span></span><br><span class="line">                            newTab[j] = loHead; <span class="comment">// 将原索引位置的节点设置为对应的头结点</span></span><br><span class="line">                        &#125;</span><br><span class="line">                        <span class="keyword">if</span> (hiTail != <span class="keyword">null</span>) &#123;</span><br><span class="line">                            hiTail.next = <span class="keyword">null</span>; <span class="comment">// 最后一个节点的next设为空</span></span><br><span class="line">                            newTab[j + oldCap] = hiHead; <span class="comment">// 将索引位置为原索引+oldCap的节点设置为对应的头结点</span></span><br><span class="line">                        &#125;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> newTab;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h2 id="9-hashmap-remove-方法"><a href="#9-hashmap-remove-方法" class="headerlink" title="9.hashmap remove()方法"></a>9.hashmap remove()方法</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> V <span class="title">remove</span><span class="params">(Object key)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt; e;</span><br><span class="line">    <span class="keyword">return</span> (e = removeNode(hash(key), key, <span class="keyword">null</span>, <span class="keyword">false</span>, <span class="keyword">true</span>)) == <span class="keyword">null</span> ?</span><br><span class="line">        <span class="keyword">null</span> : e.value;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">final</span> Node&lt;K,V&gt; <span class="title">removeNode</span><span class="params">(<span class="keyword">int</span> hash, Object key, Object value,</span></span></span><br><span class="line"><span class="function"><span class="params">                           <span class="keyword">boolean</span> matchValue, <span class="keyword">boolean</span> movable)</span> </span>&#123;</span><br><span class="line">    Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; <span class="keyword">int</span> n, index;</span><br><span class="line">    <span class="comment">// 如果table不为空并且根据hash值计算出来的索引位置不为空, 将该位置的节点赋值给p</span></span><br><span class="line">    <span class="keyword">if</span> ((tab = table) != <span class="keyword">null</span> &amp;&amp; (n = tab.length) &gt; <span class="number">0</span> &amp;&amp;</span><br><span class="line">        (p = tab[index = (n - <span class="number">1</span>) &amp; hash]) != <span class="keyword">null</span>) &#123;</span><br><span class="line">        Node&lt;K,V&gt; node = <span class="keyword">null</span>, e; K k; V v;</span><br><span class="line">        <span class="comment">// 如果p的hash值和key都与入参的相同, 则p即为目标节点, 赋值给node</span></span><br><span class="line">        <span class="keyword">if</span> (p.hash == hash &amp;&amp;</span><br><span class="line">            ((k = p.key) == key || (key != <span class="keyword">null</span> &amp;&amp; key.equals(k))))</span><br><span class="line">            node = p;</span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> ((e = p.next) != <span class="keyword">null</span>) &#123;    <span class="comment">// 否则向下遍历节点</span></span><br><span class="line">            <span class="keyword">if</span> (p <span class="keyword">instanceof</span> TreeNode)  <span class="comment">// 如果p是TreeNode则调用红黑树的方法查找节点</span></span><br><span class="line">                node = ((TreeNode&lt;K,V&gt;)p).getTreeNode(hash, key);</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                <span class="keyword">do</span> &#123;    <span class="comment">// 遍历链表查找符合条件的节点</span></span><br><span class="line">                    <span class="comment">// 当节点的hash值和key与传入的相同,则该节点即为目标节点</span></span><br><span class="line">                    <span class="keyword">if</span> (e.hash == hash &amp;&amp;</span><br><span class="line">                        ((k = e.key) == key ||</span><br><span class="line">                         (key != <span class="keyword">null</span> &amp;&amp; key.equals(k)))) &#123;</span><br><span class="line">                        node = e;    <span class="comment">// 赋值给node, 并跳出循环</span></span><br><span class="line">                        <span class="keyword">break</span>;</span><br><span class="line">                    &#125;</span><br><span class="line">                    p = e;  <span class="comment">// p节点赋值为本次结束的e</span></span><br><span class="line">                &#125; <span class="keyword">while</span> ((e = e.next) != <span class="keyword">null</span>); <span class="comment">// 指向像一个节点</span></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 如果node不为空(即根据传入key和hash值查找到目标节点)，则进行移除操作</span></span><br><span class="line">        <span class="keyword">if</span> (node != <span class="keyword">null</span> &amp;&amp; (!matchValue || (v = node.value) == value ||</span><br><span class="line">                             (value != <span class="keyword">null</span> &amp;&amp; value.equals(v)))) &#123; </span><br><span class="line">            <span class="keyword">if</span> (node <span class="keyword">instanceof</span> TreeNode)   <span class="comment">// 如果是TreeNode则调用红黑树的移除方法</span></span><br><span class="line">                ((TreeNode&lt;K,V&gt;)node).removeTreeNode(<span class="keyword">this</span>, tab, movable);</span><br><span class="line">            <span class="comment">// 走到这代表节点是普通链表节点</span></span><br><span class="line">            <span class="comment">// 如果node是该索引位置的头结点则直接将该索引位置的值赋值为node的next节点</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span> (node == p)</span><br><span class="line">                tab[index] = node.next;</span><br><span class="line">            <span class="comment">// 否则将node的上一个节点的next属性设置为node的next节点, </span></span><br><span class="line">            <span class="comment">// 即将node节点移除, 将node的上下节点进行关联(链表的移除)    </span></span><br><span class="line">            <span class="keyword">else</span> </span><br><span class="line">                p.next = node.next;</span><br><span class="line">            ++modCount; <span class="comment">// 修改次数+1</span></span><br><span class="line">            --size; <span class="comment">// table的总节点数-1</span></span><br><span class="line">            afterNodeRemoval(node); <span class="comment">// 供LinkedHashMap使用</span></span><br><span class="line">            <span class="keyword">return</span> node;    <span class="comment">// 返回被移除的节点</span></span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">null</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="总结篇"><a href="#总结篇" class="headerlink" title="总结篇"></a>总结篇</h2><ol><li>在JDK8 HashMap使用的是懒加载模式，也就是说，在默认初始化hashmap的时候，并不会在内存中创建一个长度为16的数组。而是在第一次put数据的时候才会创建。</li><li>负载因子的作用：默认负载因子为0.75.也就是说，hashmap在put数据的时候，发现数组中75%的index中都有了数据，就会进行一次扩容。每一次扩容大小均为2^n。(默认情况下，首次初始化数组长度为16，那么扩容阈值就位12)</li><li>链表转化为红黑树的条件：1.单个index中的链表长度超过8。 2.当前散列表长度打到64。</li><li>put算法：<br>1、对比hash值。如果节点已经存在，则更新原值。<br>2、如果节点不存在，则插入数组中，如果数组已经有值，则判断是否是红黑树，如果是，则调用红黑树方法插入<br>3、如果插入的是链表，插入尾部，然后判断节点数是否超过8，如果超过，则转换为红黑树<br>4、先插入的数据，后面判断是否超过阀值再进行的扩容</li></ol>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
          <category> hashmap </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 源码 </tag>
            
            <tag> hashmap </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark任务运行流程(基于yarn集群模式)源码分析（1）</title>
      <link href="/2020/06/01/spark/spark%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(1)/"/>
      <url>/2020/06/01/spark/spark%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(1)/</url>
      
        <content type="html"><![CDATA[<h1 id="Spark任务运行流程-基于yarn集群模式-源码分析（1）"><a href="#Spark任务运行流程-基于yarn集群模式-源码分析（1）" class="headerlink" title="Spark任务运行流程(基于yarn集群模式)源码分析（1）"></a>Spark任务运行流程(基于yarn集群模式)源码分析（1）</h1><p> <strong>写在前面的话</strong><br>  本文通过通俗易懂的方式，将以spark的yarn集群模式，通过源码层面去分析spark的任务调度流程。因为源码量巨大，所以只分析调度任务时所经历的主要流程。<br>  <strong>注：阅读前需要具备一点点scala基础</strong></p><h2 id="1-1-Spark核心组件"><a href="#1-1-Spark核心组件" class="headerlink" title="1.1 Spark核心组件"></a>1.1 Spark核心组件</h2><ul><li>Driver<br>Spark的驱动器节点，用于执行spark的main方法，负责实际代码的执行工作。<br>主要责任有：</li></ul><ol><li>将用户程序转化为作业(job)</li><li>在Executor之间调度任务(Task)</li><li>跟踪Executor的执行情况</li><li>通过UI展示查询运行情况</li></ol><ul><li>Executor<br>Spark Executor节点是负责在Spark作业中运行具体的任务，任务彼此之间互相独立。Spark应用启动时，Executor加点被同时启动，并且始终伴随着整个Spark用用的生命周期。<br>Executor自动启动HA机制，当某个节点运行故障，Spark应用会自动将出错节点上的任务调度到其他的节点上继续执行。<br>Executor的核心功能：</li></ul><ol><li>负责运行组成Spark的应用任务，并将结果返回Driver端</li><li>它们通过自身的块管理器（Block Manager）为用户程序中要求缓存的 RDD 提供内存式存储。RDD是直接缓存在Executor进程内的，因此任务可以在运行时充分利用缓存数据加速运算。</li></ol><ul><li>Spark通用运行流程概述<br><img src="https://s1.ax1x.com/2020/06/19/NuiIyT.png" alt="NuiIyT.png"><br>上图体现spark基本的运行流程：</li></ul><ol><li>在任务提交以后，Saprk会先启动Driver程序</li><li>随后Driver分出两条线，</li><li>1 一条从集群管理器去注册应用程序，因为有这条线，Spark才能与yarn结合。实现可插拔。</li><li>2 另一条执行main函数。  Spark的查询为懒执行，当执行到Action算子时开始反向推算，根据宽依赖进行Stage的划分，随后每一个Stage对于一个Taskset。</li><li>Task分发到执行的Executor去执行。<h1 id="Spark在yarn的提交流程"><a href="#Spark在yarn的提交流程" class="headerlink" title="Spark在yarn的提交流程"></a>Spark在yarn的提交流程</h1><h2 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h2>准备两个依赖<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.spark&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spark-yarn_2.12&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.4.5&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.spark&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;spark-core_2.12&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.4.5&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure><h2 id="2-1-指令执行入口"><a href="#2-1-指令执行入口" class="headerlink" title="2.1 指令执行入口"></a>2.1 指令执行入口</h2>在yarn运行模式下。spark会通过一个指令，向yarn提交任务。本文以官方案例，spark PI为例：<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/spark-submit \</span><br><span class="line">--class org.apache.spark.examples.SparkPi \</span><br><span class="line">--master yarn \</span><br><span class="line">./examples/jars/spark-examples_2.12-2.4.5.jar \</span><br><span class="line">10</span><br></pre></td></tr></table></figure>从指令中可以看到，这个指令式执行spark-submit，传入参数。<br><img src="https://s1.ax1x.com/2020/06/19/NKFNqO.png" alt="NKFNqO.png"><br>用文本文件打开这个文件，里面只有不到30行代码。主要带代码在最后一句。这个指令主要执行<br>文件bin目录下的spark-class的org.apache.spark.deploy.SparkSubmit类</li></ol><figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">exec "$&#123;SPARK_HOME&#125;"/bin/spark-class org.apache.spark.deploy.SparkSubmit "$@"</span><br></pre></td></tr></table></figure><p>打开spark-class可以找到<br><img src="https://s1.ax1x.com/2020/06/19/NKFcsf.png" alt="NKFcsf.png"><br>从最后一行开始。这个文件执行了</p><ol><li>CMD参数。</li><li>CMD参数用过while循环，将build_command封装进CMD</li><li>build_command配置了JVM的内存，前面的Runner封装了java的配置。<br><img src="https://s1.ax1x.com/2020/06/19/NKFHyV.png" alt="NKFHyV.png"><br>所以通过拼接，最后得出的指令为：<figure class="highlight shell"><table><tr><td class="code"><pre><span class="line">bin/java -Xmx128m -cp org.apache.spark.deploy.SparkSubmit</span><br></pre></td></tr></table></figure>这条指令通过java的指定去启动一个进程，这个进程为spark-submit。<h2 id="2-2-SparkSubmit"><a href="#2-2-SparkSubmit" class="headerlink" title="2.2 SparkSubmit"></a>2.2 SparkSubmit</h2>通过上面这条指令。可以得出，sparkSubmit这个类中一定有一个<strong>main</strong>方法作为方法的入口，去执行。所以在idea中去寻找这个类，的伴生类对象。<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> submit = <span class="keyword">new</span> <span class="type">SparkSubmit</span>() &#123;</span><br><span class="line">      self =&gt;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">override</span> <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">parseArguments</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">SparkSubmitArguments</span> = &#123;</span><br><span class="line">        <span class="keyword">new</span> <span class="type">SparkSubmitArguments</span>(args) &#123;</span><br><span class="line">          <span class="keyword">override</span> <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">logInfo</span></span>(msg: =&gt; <span class="type">String</span>): <span class="type">Unit</span> = self.logInfo(msg)</span><br><span class="line"></span><br><span class="line">          <span class="keyword">override</span> <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">logWarning</span></span>(msg: =&gt; <span class="type">String</span>): <span class="type">Unit</span> = self.logWarning(msg)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">override</span> <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">logInfo</span></span>(msg: =&gt; <span class="type">String</span>): <span class="type">Unit</span> = printMessage(msg)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">override</span> <span class="keyword">protected</span> <span class="function"><span class="keyword">def</span> <span class="title">logWarning</span></span>(msg: =&gt; <span class="type">String</span>): <span class="type">Unit</span> = printMessage(<span class="string">s"Warning: <span class="subst">$msg</span>"</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">doSubmit</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">        <span class="keyword">try</span> &#123;</span><br><span class="line">          <span class="keyword">super</span>.doSubmit(args)</span><br><span class="line">        &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">          <span class="keyword">case</span> e: <span class="type">SparkUserAppException</span> =&gt;</span><br><span class="line">            exitFn(e.exitCode)</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    submit.doSubmit(args)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>进入main方法。可以看到main方法中前面所有的方法都是在声明类信息。只有最后一行去调用了SparkSubmit的doSubmit方法，并将args作为参数传入。</li></ol><p><strong>目前的结构是：</strong></p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SparkSubmit</span><br><span class="line"></span><br><span class="line">    -- main</span><br><span class="line">    </span><br><span class="line">        &#x2F;&#x2F; 执行提交</span><br><span class="line">        &#x2F;&#x2F; args表示应用程序的命令行参数</span><br><span class="line">        -- submit.doSubmit(args)</span><br></pre></td></tr></table></figure><h3 id="2-2-1-doSubmit"><a href="#2-2-1-doSubmit" class="headerlink" title="2.2.1 doSubmit"></a>2.2.1 doSubmit</h3><p>点击进入doSubmit<br><img src="https://s1.ax1x.com/2020/06/19/NKkPOK.png" alt="NKkPOK.png"><br>代码量很少，关键的代码只有</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">val appArgs &#x3D; parseArguments(args)</span><br></pre></td></tr></table></figure><p>从字面意思，这句话对传入的args进行参数的解析。</p><h4 id="2-2-1-1-parseArguments"><a href="#2-2-1-1-parseArguments" class="headerlink" title="2.2.1.1 parseArguments"></a>2.2.1.1 parseArguments</h4><p>进入 <strong>parseArguments -&gt; SparkSubmitArguments</strong><br><img src="https://s1.ax1x.com/2020/06/19/NKkMOf.png" alt="NKkMOf.png"><br>可以看到很熟悉的东西。这个类将各种参数进行封装，封装成自己的类。<br>在下文可以看到处理的过程。但是这个并不是本文的主要内容所以略过。<br><img src="https://s1.ax1x.com/2020/06/19/NKkYfs.png" alt="NKkYfs.png"><br>在本类中可以找到一个handle的方法：<br><img src="https://s1.ax1x.com/2020/06/19/NKkUlq.png" alt="NKkUlq.png"><br>这个方法通过模式匹配对命令行的参数进行了封装。如：<br>–class org.apache.spark.examples.SparkPi <br>–master yarn <br>将 org.apache.spark.examples.SparkPi =&gt; master<br>将yarn -&gt; master<br>所以目前的结构是：</p><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SparkSubmit</span><br><span class="line"></span><br><span class="line">    -- main</span><br><span class="line">    </span><br><span class="line">        &#x2F;&#x2F; 执行提交</span><br><span class="line">        &#x2F;&#x2F; args表示应用程序的命令行参数</span><br><span class="line">        -- submit.doSubmit(args)</span><br><span class="line">        </span><br><span class="line">        &#x2F;&#x2F; 解析命令行参数</span><br><span class="line">        &#x2F;&#x2F; --master : yarn            &#x3D;&gt; master</span><br><span class="line">        &#x2F;&#x2F; --class  : xxxxx.WordCount &#x3D;&gt; mainClass</span><br><span class="line">        -- parseArguments</span><br></pre></td></tr></table></figure><p>sparkSubmit执行<strong>main</strong> -&gt; <strong>dosubmit</strong>  -&gt;  <strong>parseArguments</strong> -&gt;** new SparkSubmitArguments** -&gt; 通过<strong>handle</strong>方法，将命令行的各个参数传入到了spark程序中。</p><h4 id="2-2-1-2-action"><a href="#2-2-1-2-action" class="headerlink" title="2.2.1.2 action"></a>2.2.1.2 action</h4><p>返回doSubmit层，往下看可以看到一个action方法：</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">    appArgs.action <span class="keyword">match</span> &#123;</span><br><span class="line">      <span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">SUBMIT</span> =&gt; submit(appArgs, uninitLog)</span><br><span class="line">      <span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">KILL</span> =&gt; kill(appArgs)</span><br><span class="line">      <span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">REQUEST_STATUS</span> =&gt; requestStatus(appArgs)</span><br><span class="line">      <span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">PRINT_VERSION</span> =&gt; printVersion()</span><br><span class="line">    &#125;</span><br><span class="line">`</span><br></pre></td></tr></table></figure><p>通过代码可以得知appargs通过模式匹配执行了action，由于没有case _的选项，所以action一定在某个地方被赋值了。<br>点击进入action所在的<strong>SparkSubmitArguments</strong>，可以找到这样一行代码：<br><img src="https://s1.ax1x.com/2020/06/19/NKkB0U.png" alt="NKkB0U.png"><br>通过一定的scala基础，可以分析出action在这里被赋值上了SUBMIT<br>最后action走的是</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="type">SparkSubmitAction</span>.<span class="type">SUBMIT</span> =&gt; submit(appArgs, uninitLog)</span><br></pre></td></tr></table></figure><p>这一行代码。</p><h3 id="2-2-2-submit-appArgs-uninitLog"><a href="#2-2-2-submit-appArgs-uninitLog" class="headerlink" title="2.2.2 submit(appArgs, uninitLog)"></a>2.2.2 submit(appArgs, uninitLog)</h3><p>进入action的submit函数<br><img src="https://s1.ax1x.com/2020/06/19/NKk40O.png" alt="NKk40O.png"><br>里面有一个doRunMain函数，由于没有调用这个函数，所以这个函数不被执行，先跳过，看下面的if-else方法</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (args.isStandaloneCluster &amp;&amp; args.useRest) &#123;</span><br><span class="line">    <span class="keyword">try</span> &#123;</span><br><span class="line">      logInfo(<span class="string">"Running Spark using the REST application submission protocol."</span>)</span><br><span class="line">      doRunMain()</span><br><span class="line">    &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">      <span class="comment">// Fail over to use the legacy submission gateway</span></span><br><span class="line">      <span class="keyword">case</span> e: <span class="type">SubmitRestConnectionException</span> =&gt;</span><br><span class="line">        logWarning(<span class="string">s"Master endpoint <span class="subst">$&#123;args.master&#125;</span> was not a REST server. "</span> +</span><br><span class="line">          <span class="string">"Falling back to legacy submission gateway instead."</span>)</span><br><span class="line">        args.useRest = <span class="literal">false</span></span><br><span class="line">        submit(args, <span class="literal">false</span>)</span><br><span class="line">    &#125;</span><br><span class="line">  <span class="comment">// In all other modes, just run the main class as prepared</span></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    doRunMain()</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>由于本文是基于yarn部署环境。所以直接查看else中的doRunMain方法</p><h4 id="2-2-2-1-doRunMain"><a href="#2-2-2-1-doRunMain" class="headerlink" title="2.2.2.1 doRunMain"></a>2.2.2.1 doRunMain</h4><p>doRunMain方法中，if函数判断是否有代理用户，当前执行命令并没有设定，所以执行else中的<strong>runMain</strong>方法</p><h3 id="2-2-3-runMain"><a href="#2-2-3-runMain" class="headerlink" title="2.2.3 runMain"></a>2.2.3 runMain</h3><p><img src="https://s1.ax1x.com/2020/06/19/NKkb9A.png" alt="NKkb9A.png"><br>这个函数中开始准备做提交的内容。</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> (childArgs, childClasspath, sparkConf, childMainClass) = prepareSubmitEnvironment(args)</span><br></pre></td></tr></table></figure><p>这个函数关键信息也在第一句，准备提交环境。</p><p>加下来：</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//设定类加载器。</span></span><br><span class="line"> <span class="type">Thread</span>.currentThread.setContextClassLoader(loader)</span><br></pre></td></tr></table></figure><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//加载和获取指定名称的类信息</span></span><br><span class="line"> mainClass = <span class="type">Utils</span>.classForName(childMainClass)</span><br></pre></td></tr></table></figure><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//动态(反射)创建对象</span></span><br><span class="line"> mainClass.newInstance().asInstanceOf[<span class="type">SparkApplication</span>]</span><br><span class="line"> <span class="comment">//同时在之后的代码调用start方法</span></span><br><span class="line"> app.start(childArgs.toArray, sparkConf)</span><br></pre></td></tr></table></figure><p><strong>小结回顾</strong><br>进入start方法，会发现start是一个抽象类。<br>所以，代码一定在之前就已经被实现。<br>回顾app方法，是从<strong>mainClass.newInstance().asInstanceOf[SparkApplication]</strong>这个方法过来，<br>mainClass是从<strong>mainClass = Utils.classForName(childMainClass)</strong>得到的类信息<br>childMainClass是<strong>val (childArgs, childClasspath, sparkConf, childMainClass) = prepareSubmitEnvironment(args)</strong>准备提交环境的时候返回的结果。<br>所以以上的代码就连成了串，关键在于<strong>prepareSubmitEnvironment</strong></p><h3 id="2-2-4-prepareSubmitEnvironment"><a href="#2-2-4-prepareSubmitEnvironment" class="headerlink" title="2.2.4 prepareSubmitEnvironment"></a>2.2.4 prepareSubmitEnvironment</h3><ol><li>进入 prepareSubmitEnvironment方法<br><img src="https://s1.ax1x.com/2020/06/19/NKk7hd.png" alt="NKk7hd.png"><br>这是一个代码量非常大的函数</li><li>直接看末尾处，<strong>748行处(childArgs, childClasspath, sparkConf, childMainClass)</strong>这是函数的返回结果，从返回结果往上推，能找到赋值的地方。</li><li>查找<strong>childMainClass</strong>跟着提示往上走，会找到这样一个代码段<br><img src="https://s1.ax1x.com/2020/06/19/NKAi3n.png" alt="NKAi3n.png"><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">childMainClass = <span class="type">YARN_CLUSTER_SUBMIT_CLASS</span></span><br></pre></td></tr></table></figure>这里是Yarn的cluster模式，进入YARN_CLUSTER_SUBMIT_CLASS可以看到完整的类对象为<strong>org.apache.spark.deploy.yarn.YarnClusterApplication</strong></li><li>继续查找会看到client模式的代码<br><img src="https://s1.ax1x.com/2020/06/19/NKAP9s.png" alt="NKAP9s.png"><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">childMainClass = args.mainClass</span><br></pre></td></tr></table></figure>而mainClass在前面已经提到为–class的值<br>所以目前的结构是：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">SparkSubmit</span><br><span class="line"></span><br><span class="line">    -- main</span><br><span class="line">    </span><br><span class="line">        &#x2F;&#x2F; 执行提交</span><br><span class="line">        &#x2F;&#x2F; args表示应用程序的命令行参数</span><br><span class="line">        -- submit.doSubmit(args)</span><br><span class="line">        </span><br><span class="line">        &#x2F;&#x2F; 解析命令行参数</span><br><span class="line">        &#x2F;&#x2F; --master : yarn            &#x3D;&gt; master</span><br><span class="line">        &#x2F;&#x2F; --class  : xxxxx.WordCount &#x3D;&gt; mainClass</span><br><span class="line">        -- parseArguments</span><br><span class="line">        </span><br><span class="line">        &#x2F;&#x2F; </span><br><span class="line">        -- submit</span><br><span class="line">            &#x2F;&#x2F; 执行主程序</span><br><span class="line">            -- doRunMain</span><br><span class="line">            </span><br><span class="line">                &#x2F;&#x2F; 执行主程序</span><br><span class="line">                -- runMain</span><br><span class="line">                </span><br><span class="line">                    &#x2F;&#x2F; childArgs</span><br><span class="line">                    &#x2F;&#x2F; childClasspath</span><br><span class="line">                    &#x2F;&#x2F; sparkConf</span><br><span class="line">                    &#x2F;&#x2F; childMainClass</span><br><span class="line">                    &#x2F;&#x2F; 准备提交的环境</span><br><span class="line">                    -- prepareSubmitEnvironment(args)</span><br><span class="line">                    </span><br><span class="line">                        &#x2F;&#x2F; client        &#x3D;&gt; xxxxx.WordCount</span><br><span class="line">                        &#x2F;&#x2F; isYarnCluster &#x3D;&gt; org.apache.spark.deploy.yarn.YarnClusterApplication</span><br><span class="line">                        -- (childArgs, childClasspath, sparkConf, childMainClass)</span><br><span class="line">                    </span><br><span class="line">                    &#x2F;&#x2F; 设定类加载器</span><br><span class="line">                    -- Thread.currentThread.setContextClassLoader(loader)</span><br><span class="line">                    </span><br><span class="line">                    &#x2F;&#x2F; 加载和获取指定名称的类信息</span><br><span class="line">                    -- mainClass &#x3D; Utils.classForName(childMainClass)</span><br><span class="line">                    </span><br><span class="line">                    &#x2F;&#x2F; 动态(反射)创建对象</span><br><span class="line">                    -- app &#x3D; mainClass.newInstance().asInstanceOf[SparkApplication]</span><br><span class="line">                    </span><br><span class="line">                    -- app.start</span><br></pre></td></tr></table></figure></li></ol><p><strong>到此SparkSubmit就已经结束</strong></p>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark源码 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark任务运行流程(基于yarn集群模式)源码分析（2）</title>
      <link href="/2020/06/01/spark/spark%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(2)/"/>
      <url>/2020/06/01/spark/spark%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(2)/</url>
      
        <content type="html"><![CDATA[<h1 id="Spark任务运行流程-基于yarn集群模式-源码分析（2）"><a href="#Spark任务运行流程-基于yarn集群模式-源码分析（2）" class="headerlink" title="Spark任务运行流程(基于yarn集群模式)源码分析（2）"></a>Spark任务运行流程(基于yarn集群模式)源码分析（2）</h1><h2 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h2><p>前文的sparkSubmit阶段已经结束。可以看到yarn集群最后是调用了command(Cluster) = bin/java org.apache.spark.deploy.yarn.ApplicationMaster<br>在源码中搜索 org.apache.spark.deploy.yarn.ApplicationMaster</p><h2 id="2-3-YarnClusterApplication"><a href="#2-3-YarnClusterApplication" class="headerlink" title="2.3 YarnClusterApplication"></a>2.3 YarnClusterApplication</h2><p><img src="https://s1.ax1x.com/2020/06/19/NKlq3T.png" alt="NKlq3T.png"><br>从图中可以看到一共有三个参数，<br>ClientArguments<br>Client<br>run</p><ol><li>new ClientArguments(args）<br>进入这个类很容易可以看到之前的命令参数再次被封装起来。</li><li>new Client<br><img src="https://s1.ax1x.com/2020/06/19/NK3EWV.png" alt="NK3EWV.png"><br>这里可以看到<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">val</span> yarnClient = <span class="type">YarnClient</span>.createYarnClient</span><br></pre></td></tr></table></figure>这里Client创建了一个yarn的客户端。<br>所以在当前的环境中应该已经包含了yarn的服务器，ResourceManager与NodeManager</li><li>run<br><img src="https://s1.ax1x.com/2020/06/19/NK3X79.png" alt="NK3X79.png"><br>this.appId = submitApplication()此方法用于提交应用<ul><li>进入submitApplication<br><img src="https://s1.ax1x.com/2020/06/19/NK85HH.png" alt="NK85HH.png"><br>这里初始化了yarnClient客户端，与启动了yarnClient。使sparkSubmit能与yarn开始通信<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//179行</span></span><br><span class="line">      <span class="keyword">val</span> containerContext = createContainerLaunchContext(newAppResponse)</span><br><span class="line">      <span class="keyword">val</span> appContext = createApplicationSubmissionContext(newApp, containerContext)</span><br><span class="line"></span><br><span class="line"> <span class="comment">//184行</span></span><br><span class="line"> yarnClient.submitApplication(appContext)</span><br></pre></td></tr></table></figure>开始向yarnClient提交应用，参数appContext为提交的内容<br>createContainerLaunchContext:主要封装JVM的参数，与封装ApplicationMaster的参数<br>createApplicationSubmissionContext：主要封装框架的参数信息</li></ul></li></ol><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="type">YarnClusterApplication</span></span><br><span class="line">    -- start</span><br><span class="line">    </span><br><span class="line">        <span class="comment">// 封装参数</span></span><br><span class="line">        <span class="comment">// --class xxxxx.WordCount</span></span><br><span class="line">        -- <span class="keyword">new</span> <span class="type">ClientArguments</span></span><br><span class="line">    </span><br><span class="line">        -- <span class="keyword">new</span> <span class="type">Client</span></span><br><span class="line">            <span class="comment">// 建立和RM之间的联系</span></span><br><span class="line">            -- yarnClient = <span class="type">YarnClient</span>.createYarnClient</span><br><span class="line">        -- run</span><br><span class="line">            <span class="comment">// 提交应用</span></span><br><span class="line">            -- submitApplication</span><br><span class="line">            </span><br><span class="line">                -- yarnClient.init</span><br><span class="line">                -- yarnClient.start</span><br><span class="line">                 <span class="comment">// 环境准备</span></span><br><span class="line">                <span class="comment">// command(Cluster) = bin/java org.apache.spark.deploy.yarn.ApplicationMaster</span></span><br><span class="line">                <span class="comment">// command(Client)  = bin/java org.apache.spark.deploy.yarn.ExecutorLauncher</span></span><br><span class="line">                -- createContainerLaunchContext(newAppResponse)</span><br><span class="line">                -- createApplicationSubmissionContext(newApp, containerContext)</span><br><span class="line">                </span><br><span class="line">                <span class="comment">// 向Yarn提交应用</span></span><br><span class="line">                -- yarnClient.submitApplication(appContext)</span><br><span class="line">                </span><br><span class="line">                    -- rmClient.submitApplication</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark源码 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark任务运行流程(基于yarn集群模式)源码分析（3）</title>
      <link href="/2020/06/01/spark/spark%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(3)/"/>
      <url>/2020/06/01/spark/spark%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(3)/</url>
      
        <content type="html"><![CDATA[<h1 id="Spark任务运行流程-基于yarn集群模式-源码分析（3）"><a href="#Spark任务运行流程-基于yarn集群模式-源码分析（3）" class="headerlink" title="Spark任务运行流程(基于yarn集群模式)源码分析（3）"></a>Spark任务运行流程(基于yarn集群模式)源码分析（3）</h1><h2 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h2><p><img src="https://s1.ax1x.com/2020/06/19/NKN3Yd.png" alt="NKN3Yd.png"></p><h2 id="2-4-ApplicationMaster"><a href="#2-4-ApplicationMaster" class="headerlink" title="2.4 ApplicationMaster"></a>2.4 ApplicationMaster</h2><p>在sparksubmit与yarn建立了连接后，RM需要建立AM，并在AM中执行命令。<br>搜索<strong>org.apache.spark.deploy.yarn.ApplicationMaster</strong>，查看伴生类对象的main方法。</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">  <span class="type">SignalUtils</span>.registerLogger(log)</span><br><span class="line">  <span class="keyword">val</span> amArgs = <span class="keyword">new</span> <span class="type">ApplicationMasterArguments</span>(args)</span><br><span class="line">  master = <span class="keyword">new</span> <span class="type">ApplicationMaster</span>(amArgs)</span><br><span class="line">  <span class="type">System</span>.exit(master.run())</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里的主要方法为</p><ol><li>new ApplicationMasterArguments    封装了命令行参数</li><li>new ApplicationMaster</li><li>run()<h3 id="2-4-1-ApplicationMaster"><a href="#2-4-1-ApplicationMaster" class="headerlink" title="2.4.1 ApplicationMaster"></a>2.4.1 ApplicationMaster</h3>点击查看ApplicationMaster的代码：</li><li>sparkConf //63行</li><li>yarnConf  //83行</li><li>userClassLoader //85行</li><li>client = doAsUser { new YarnRMClient() }    //122行<br>从client可以看到，AM中含有Yarn的RM的连接<h3 id="2-4-2-run"><a href="#2-4-2-run" class="headerlink" title="2.4.2 run()"></a>2.4.2 run()</h3><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//run的函数很简单</span></span><br><span class="line">  <span class="keyword">final</span> <span class="function"><span class="keyword">def</span> <span class="title">run</span></span>(): <span class="type">Int</span> = &#123;</span><br><span class="line">    doAsUser &#123;</span><br><span class="line">      runImpl()</span><br><span class="line">    &#125;</span><br><span class="line">    exitCode</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>进入runImpl()<br>runImpl()中包含了两个重要的代码<figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> appAttemptId = client.getAttemptId()</span><br><span class="line"></span><br><span class="line"><span class="comment">//304行</span></span><br><span class="line"><span class="keyword">if</span> (isClusterMode) &#123;</span><br><span class="line">        runDriver()</span><br><span class="line"> &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    runExecutorLauncher()</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>appAttemptId为Yarn的全局ID，一个任务仅包含一个ID<br>集群模式执行了runDriver()<br>而客户端模式执行runExecutorLauncher()<h4 id="2-4-2-1-runDriver"><a href="#2-4-2-1-runDriver" class="headerlink" title="2.4.2.1 runDriver()"></a>2.4.2.1 runDriver()</h4>进入runDriver()<br><img src="https://s1.ax1x.com/2020/06/19/NK0hWQ.png" alt="NK0hWQ.png"></li></ol><ul><li>startUserApplication() 启动用户的方法<br>  进入 startUserApplication方法。很容易看到  <figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">val</span> mainMethod = userClassLoader.loadClass(args.userClass)</span><br><span class="line">     .getMethod(<span class="string">"main"</span>, classOf[<span class="type">Array</span>[<span class="type">String</span>]])</span><br></pre></td></tr></table></figure><ol><li>这个方法通过类加载器，加载了–class的值，并获取了类中的main方法</li><li>val userThread = new Thread //这个userThread在之后被命名为Driver</li><li>userThread.setContextClassLoader(userClassLoader)<br>   userThread.setName(“Driver”)<pre><code>userThread.start()//run方法中判断main方法是否为静态。并调用main方法    userThread</code></pre>这条线创建了Driver线程，执行应用程序</li></ol></li><li>val sc = ThreadUtils.awaitResult(sparkContextPromise.future,Duration(totalWaitTime, TimeUnit.MILLISECONDS))  这个线程阻塞，等待sparkcontext的创建</li></ul><h4 id="2-4-2-2-registerAM"><a href="#2-4-2-2-registerAM" class="headerlink" title="2.4.2.2 registerAM"></a>2.4.2.2 registerAM</h4><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">if</span> (sc != <span class="literal">null</span>) &#123;</span><br><span class="line">        rpcEnv = sc.env.rpcEnv</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> userConf = sc.getConf</span><br><span class="line">        <span class="keyword">val</span> host = userConf.get(<span class="string">"spark.driver.host"</span>)</span><br><span class="line">        <span class="keyword">val</span> port = userConf.get(<span class="string">"spark.driver.port"</span>).toInt</span><br><span class="line">        registerAM(host, port, userConf, sc.ui.map(_.webUrl))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">val</span> driverRef = rpcEnv.setupEndpointRef(</span><br><span class="line">          <span class="type">RpcAddress</span>(host, port),</span><br><span class="line">          <span class="type">YarnSchedulerBackend</span>.<span class="type">ENDPOINT_NAME</span>)</span><br><span class="line">        createAllocator(driverRef, userConf)</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure><ol><li>运行Rpc通讯环境</li><li>registerAM(host, port, userConf, sc.ui.map(_.webUrl)) 向RM注册Driver，申请资源</li><li>rpcEnv.setupEndpointRef -&gt; RM向AM返回资源列表，并分配可用资源<br>小结：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 封装命令行参数</span><br><span class="line">&#x2F;&#x2F; --class xxxx.WordCount  &#x3D;》userClass</span><br><span class="line">-- new ApplicationMasterArguments</span><br><span class="line"></span><br><span class="line">-- new ApplicationMaster</span><br><span class="line"></span><br><span class="line">-- sparkConf</span><br><span class="line">-- yarnConf</span><br><span class="line">-- userClassLoader</span><br><span class="line">&#x2F;&#x2F; AM保有Yarn RM的客户端连接</span><br><span class="line">-- client &#x3D; new YarnRMClient()</span><br><span class="line"></span><br><span class="line">-- run</span><br><span class="line"></span><br><span class="line">-- runImpl</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 客户端模式执行此方法</span><br><span class="line">-- runExecutorLauncher</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 集群模式执行此方法</span><br><span class="line">            -- runDriver</span><br><span class="line"></span><br><span class="line">-- startUserApplication</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 反射获取应用程序的main方法</span><br><span class="line">-- val mainMethod &#x3D; userClassLoader.loadClass(args.userClass)</span><br><span class="line">.getMethod(&quot;main&quot;, classOf[Array[String]])</span><br><span class="line"></span><br><span class="line">-- new Thread</span><br><span class="line"></span><br><span class="line">--  userThread.setName(&quot;Driver&quot;)</span><br><span class="line">userThread.start()</span><br><span class="line"></span><br><span class="line">-- run </span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 创建运行线程，运行应用程序的main方法</span><br><span class="line">                        &#x2F;&#x2F; WordCount开始执行</span><br><span class="line">                        -- mainMethod.invoke</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; RPC 通信环境 </span><br><span class="line">-- rpcEnv &#x3D; sc.env.rpcEnv</span><br><span class="line"></span><br><span class="line">-- registerAM</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F; 获取可分配Yarn的资源</span><br><span class="line">            -- allocator.allocateResources()</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F; 分配Yarn的资源</span><br><span class="line">            -- handleAllocatedContainers</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F; 容器本地化 ：移动数据不如移动计算</span><br><span class="line"></span><br><span class="line">            &#x2F;&#x2F; 运行选择后的容器资源</span><br><span class="line">            -- runAllocatedContainers</span><br><span class="line"></span><br><span class="line">                &#x2F;&#x2F; 根据容器的数量启动线程</span><br><span class="line">                &#x2F;&#x2F;</span><br><span class="line">                -- new ExecutorRunnable.run</span><br><span class="line"></span><br><span class="line">                -- nmClient &#x3D; NMClient.createNMClient()</span><br><span class="line"></span><br><span class="line">                -- startContainer</span><br><span class="line"></span><br><span class="line">                &#x2F;&#x2F; command &#x3D; bin&#x2F;java org.apache.spark.executor.CoarseGrainedExecutorBackend</span><br><span class="line">                -- prepareCommand</span><br><span class="line"></span><br><span class="line">            -- nmClient.startContainer</span><br></pre></td></tr></table></figure></li></ol>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark源码 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Spark任务运行流程(基于yarn集群模式)源码分析（4）</title>
      <link href="/2020/06/01/spark/spark%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(4)/"/>
      <url>/2020/06/01/spark/spark%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90(4)/</url>
      
        <content type="html"><![CDATA[<h1 id="Spark任务运行流程-基于yarn集群模式-源码分析（4）"><a href="#Spark任务运行流程-基于yarn集群模式-源码分析（4）" class="headerlink" title="Spark任务运行流程(基于yarn集群模式)源码分析（4）"></a>Spark任务运行流程(基于yarn集群模式)源码分析（4）</h1><h2 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h2><p><img src="https://s1.ax1x.com/2020/06/19/NKxE40.png" alt="NKxE40.png"><br>AM创建了Driver线程后，连接NM启动CoarseGrainedExecutorBackend</p><h2 id="2-5-CoarseGrainedExecutorBackend"><a href="#2-5-CoarseGrainedExecutorBackend" class="headerlink" title="2.5 CoarseGrainedExecutorBackend"></a>2.5 CoarseGrainedExecutorBackend</h2><p>搜索 CoarseGrainedExecutorBackend点击伴生类对象，寻找Main方法<br><img src="https://s1.ax1x.com/2020/06/19/NKxY8K.png" alt="NKxY8K.png"><br>Main方法总，分解了参数。<br>并启动了run方法</p><h3 id="2-5-1-run"><a href="#2-5-1-run" class="headerlink" title="2.5.1 run"></a>2.5.1 run</h3><p><img src="https://s1.ax1x.com/2020/06/19/NKxwbd.png" alt="NKxwbd.png"></p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//RpcEnv创建了一个RPC的通讯环境</span></span><br><span class="line"><span class="keyword">val</span> fetcher = <span class="type">RpcEnv</span>.create(</span><br><span class="line">        <span class="string">"driverPropsFetcher"</span>,</span><br><span class="line">        hostname,</span><br><span class="line">        <span class="number">-1</span>,</span><br><span class="line">        executorConf,</span><br><span class="line">        <span class="keyword">new</span> <span class="type">SecurityManager</span>(executorConf),</span><br><span class="line">        clientMode = <span class="literal">true</span>)</span><br><span class="line">        </span><br><span class="line"><span class="comment">//得到driver</span></span><br><span class="line"><span class="keyword">val</span> driver = fetcher.setupEndpointRefByURI(driverUrl)</span><br><span class="line"></span><br><span class="line"><span class="comment">//创建执行器环境</span></span><br><span class="line"><span class="keyword">val</span> env = <span class="type">SparkEnv</span>.createExecutorEnv(</span><br><span class="line">        driverConf, executorId, hostname, cores, cfg.ioEncryptionKey, isLocal = <span class="literal">false</span>)</span><br><span class="line">        </span><br><span class="line"><span class="comment">//创建一个名叫Excutor的终端，并与Driver互相通信</span></span><br><span class="line">env.rpcEnv.setupEndpoint(<span class="string">"Executor"</span>, <span class="keyword">new</span> <span class="type">CoarseGrainedExecutorBackend</span>(</span><br><span class="line">env.rpcEnv, driverUrl, executorId, hostname, cores, userClassPath, env))</span><br></pre></td></tr></table></figure><h3 id="2-5-2-inbox"><a href="#2-5-2-inbox" class="headerlink" title="2.5.2 inbox"></a>2.5.2 inbox</h3><p>进入setupEndpoint为一个抽象方法<br>获取实现类NettyRpcEnv找到实现setupEndpoint的方法</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//注册通讯终端</span></span><br><span class="line"> <span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">setupEndpoint</span></span>(name: <span class="type">String</span>, endpoint: <span class="type">RpcEndpoint</span>): <span class="type">RpcEndpointRef</span> = &#123;</span><br><span class="line">    dispatcher.registerRpcEndpoint(name, endpoint)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>进入registerRpcEndpoint</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//通讯终端中有一个终端的集合，里面存放了终端的消息</span></span><br><span class="line"><span class="keyword">if</span> (endpoints.putIfAbsent(name, <span class="keyword">new</span> <span class="type">EndpointData</span>(name, endpoint, endpointRef)) != <span class="literal">null</span>) &#123;<span class="keyword">throw</span> <span class="keyword">new</span> <span class="type">IllegalArgumentException</span>(<span class="string">s"There is already an RpcEndpoint called <span class="subst">$name</span>"</span>)&#125;</span><br></pre></td></tr></table></figure><p>进入EndpointData</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//inbox作为收件箱</span></span><br><span class="line">  <span class="keyword">private</span> <span class="class"><span class="keyword">class</span> <span class="title">EndpointData</span>(<span class="params"></span></span></span><br><span class="line"><span class="class"><span class="params">      val name: <span class="type">String</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">      val endpoint: <span class="type">RpcEndpoint</span>,</span></span></span><br><span class="line"><span class="class"><span class="params">      val ref: <span class="type">NettyRpcEndpointRef</span></span>) </span>&#123;</span><br><span class="line">    <span class="keyword">val</span> inbox = <span class="keyword">new</span> <span class="type">Inbox</span>(ref, endpoint)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><p>进入inbox</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">//将消息放入LinkedList的收件箱</span></span><br><span class="line"><span class="meta">@GuardedBy</span>(<span class="string">"this"</span>)</span><br><span class="line"><span class="keyword">protected</span> <span class="keyword">val</span> messages = <span class="keyword">new</span> java.util.<span class="type">LinkedList</span>[<span class="type">InboxMessage</span>]()</span><br><span class="line"></span><br><span class="line"><span class="comment">//当注册完毕，通讯终端应该启动</span></span><br><span class="line">inbox.synchronized &#123;</span><br><span class="line">    messages.add(<span class="type">OnStart</span>)</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">//调用通讯终端的onStart方法启动</span></span><br><span class="line"><span class="keyword">case</span> <span class="type">OnStart</span> =&gt; endpoint.onStart()</span><br></pre></td></tr></table></figure><h3 id="2-5-3-onStrart"><a href="#2-5-3-onStrart" class="headerlink" title="2.5.3 onStrart"></a>2.5.3 onStrart</h3><p>在通讯终端(CoarseGrainedExecutorBackend)搜索onStrat方法</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">override</span> <span class="function"><span class="keyword">def</span> <span class="title">onStart</span></span>() &#123;</span><br><span class="line">    logInfo(<span class="string">"Connecting to driver: "</span> + driverUrl)</span><br><span class="line">    rpcEnv.asyncSetupEndpointRefByURI(driverUrl).flatMap &#123; ref =&gt;</span><br><span class="line">      <span class="comment">// This is a very fast action so we can use "ThreadUtils.sameThread"</span></span><br><span class="line">      <span class="comment">//拿到Driver的引用</span></span><br><span class="line">      driver = <span class="type">Some</span>(ref)</span><br><span class="line">      <span class="comment">//想Driver请求，已经注册执行器</span></span><br><span class="line">      ref.ask[<span class="type">Boolean</span>](<span class="type">RegisterExecutor</span>(executorId, self, hostname, cores, extractLogUrls))</span><br><span class="line">    &#125;(<span class="type">ThreadUtils</span>.sameThread).onComplete &#123;</span><br><span class="line">      <span class="comment">// This is a very fast action so we can use "ThreadUtils.sameThread"</span></span><br><span class="line">      <span class="keyword">case</span> <span class="type">Success</span>(msg) =&gt;</span><br><span class="line">        <span class="comment">// Always receive `true`. Just ignore it</span></span><br><span class="line">      <span class="keyword">case</span> <span class="type">Failure</span>(e) =&gt;</span><br><span class="line">        exitExecutor(<span class="number">1</span>, <span class="string">s"Cannot register with driver: <span class="subst">$driverUrl</span>"</span>, e, notifyDriver = <span class="literal">false</span>)</span><br><span class="line">    &#125;(<span class="type">ThreadUtils</span>.sameThread)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure><h3 id="2-5-3-Driver回复-SchedulerBackend"><a href="#2-5-3-Driver回复-SchedulerBackend" class="headerlink" title="2.5.3 Driver回复(SchedulerBackend)"></a>2.5.3 Driver回复(SchedulerBackend)</h3><p>Driver响应Executor的回复在sparkContext中。<br>里面有一个字段为</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="keyword">var</span> _schedulerBackend: <span class="type">SchedulerBackend</span> = _</span><br></pre></td></tr></table></figure><p>SchedulerBackend为用来做后台通讯。<br>进入SchedulerBackend</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">private</span>[spark] <span class="class"><span class="keyword">trait</span> <span class="title">SchedulerBackend</span> </span>&#123;</span><br></pre></td></tr></table></figure><p>通过查找特质类找到了CoarseGrainedSchedulerBackend这个类<br>在类种搜索Executor发送的消息RegisterExecutor<br>找到了</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="keyword">case</span> <span class="type">RegisterExecutor</span>(executorId, executorRef, hostname, cores, logUrls) =&gt;</span><br><span class="line">        <span class="keyword">if</span> (executorDataMap.contains(executorId)) &#123;</span><br><span class="line">          executorRef.send(<span class="type">RegisterExecutorFailed</span>(<span class="string">"Duplicate executor ID: "</span> + executorId))</span><br><span class="line">          context.reply(<span class="literal">true</span>)</span><br><span class="line">        &#125; <span class="keyword">else</span> <span class="keyword">if</span> (scheduler.nodeBlacklist.contains(hostname)) &#123;</span><br><span class="line">          <span class="comment">// If the cluster manager gives us an executor on a blacklisted node (because it</span></span><br><span class="line">          <span class="comment">// already started allocating those resources before we informed it of our blacklist,</span></span><br><span class="line">          <span class="comment">// or if it ignored our blacklist), then we reject that executor immediately.</span></span><br><span class="line">          logInfo(<span class="string">s"Rejecting <span class="subst">$executorId</span> as it has been blacklisted."</span>)</span><br><span class="line">          executorRef.send(<span class="type">RegisterExecutorFailed</span>(<span class="string">s"Executor is blacklisted: <span class="subst">$executorId</span>"</span>))</span><br><span class="line">          context.reply(<span class="literal">true</span>)</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// If the executor's rpc env is not listening for incoming connections, `hostPort`</span></span><br><span class="line">          <span class="comment">// will be null, and the client connection should be used to contact the executor.</span></span><br><span class="line">          <span class="keyword">val</span> executorAddress = <span class="keyword">if</span> (executorRef.address != <span class="literal">null</span>) &#123;</span><br><span class="line">              executorRef.address</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">              context.senderAddress</span><br><span class="line">            &#125;</span><br><span class="line">          logInfo(<span class="string">s"Registered executor <span class="subst">$executorRef</span> (<span class="subst">$executorAddress</span>) with ID <span class="subst">$executorId</span>"</span>)</span><br><span class="line">          <span class="comment">//更新注册地址</span></span><br><span class="line">          addressToExecutorId(executorAddress) = executorId</span><br><span class="line">          <span class="comment">//更新总共的核数，跟新资源列表</span></span><br><span class="line">          totalCoreCount.addAndGet(cores)</span><br><span class="line">          totalRegisteredExecutors.addAndGet(<span class="number">1</span>)</span><br><span class="line">          <span class="keyword">val</span> data = <span class="keyword">new</span> <span class="type">ExecutorData</span>(executorRef, executorAddress, hostname,</span><br><span class="line">            cores, cores, logUrls)</span><br><span class="line">          <span class="comment">// This must be synchronized because variables mutated</span></span><br><span class="line">          <span class="comment">// in this block are read when requesting executors</span></span><br><span class="line">          <span class="type">CoarseGrainedSchedulerBackend</span>.<span class="keyword">this</span>.synchronized &#123;</span><br><span class="line">            executorDataMap.put(executorId, data)</span><br><span class="line">            <span class="keyword">if</span> (currentExecutorIdCounter &lt; executorId.toInt) &#123;</span><br><span class="line">              currentExecutorIdCounter = executorId.toInt</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (numPendingExecutors &gt; <span class="number">0</span>) &#123;</span><br><span class="line">              numPendingExecutors -= <span class="number">1</span></span><br><span class="line">              logDebug(<span class="string">s"Decremented number of pending executors (<span class="subst">$numPendingExecutors</span> left)"</span>)</span><br><span class="line">            &#125;</span><br><span class="line">          &#125;</span><br><span class="line">          <span class="comment">//回复Executor，注册完毕(不需要回复)</span></span><br><span class="line">          executorRef.send(<span class="type">RegisteredExecutor</span>)</span><br><span class="line">          <span class="comment">// Note: some tests expect the reply to come after we put the executor in the map</span></span><br><span class="line">          context.reply(<span class="literal">true</span>)</span><br><span class="line">          listenerBus.post(</span><br><span class="line">            <span class="type">SparkListenerExecutorAdded</span>(<span class="type">System</span>.currentTimeMillis(), executorId, data))</span><br><span class="line">          makeOffers()</span><br><span class="line">        &#125;</span><br></pre></td></tr></table></figure><h3 id="2-5-4-Executor收到Driver的回应"><a href="#2-5-4-Executor收到Driver的回应" class="headerlink" title="2.5.4 Executor收到Driver的回应"></a>2.5.4 Executor收到Driver的回应</h3><p>在CoarseGrainedExecutorBackend中寻找RegisteredExecutor</p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line">verride <span class="function"><span class="keyword">def</span> <span class="title">receive</span></span>: <span class="type">PartialFunction</span>[<span class="type">Any</span>, <span class="type">Unit</span>] = &#123;</span><br><span class="line">    <span class="keyword">case</span> <span class="type">RegisteredExecutor</span> =&gt;</span><br><span class="line">      logInfo(<span class="string">"Successfully registered with driver"</span>)</span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">      <span class="comment">//开始注册Executor</span></span><br><span class="line">        executor = <span class="keyword">new</span> <span class="type">Executor</span>(executorId, hostname, env, userClassPath, isLocal = <span class="literal">false</span>)</span><br><span class="line">      &#125; <span class="keyword">catch</span> &#123;</span><br><span class="line">        <span class="keyword">case</span> <span class="type">NonFatal</span>(e) =&gt;</span><br><span class="line">          exitExecutor(<span class="number">1</span>, <span class="string">"Unable to create executor due to "</span> + e.getMessage, e)</span><br><span class="line">      &#125;</span><br></pre></td></tr></table></figure><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p><img src="https://s1.ax1x.com/2020/06/19/NMCsc6.png" alt="NMCsc6.png"></p>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark源码 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>groupByKey与ReduceByKey的区别</title>
      <link href="/2020/05/23/spark/groupByKey%E4%B8%8EReduceByKey%E7%9A%84%E5%8C%BA%E5%88%AB/"/>
      <url>/2020/05/23/spark/groupByKey%E4%B8%8EReduceByKey%E7%9A%84%E5%8C%BA%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h1 id="groupByKey与ReduceByKey的区别"><a href="#groupByKey与ReduceByKey的区别" class="headerlink" title="groupByKey与ReduceByKey的区别"></a>groupByKey与ReduceByKey的区别</h1><p><strong>groupByKey</strong></p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupByKey</span></span>(): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">Iterable</span>[<span class="type">V</span>])]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupByKey</span></span>(numPartitions: <span class="type">Int</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">Iterable</span>[<span class="type">V</span>])]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">groupByKey</span></span>(partitioner: <span class="type">Partitioner</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">Iterable</span>[<span class="type">V</span>])]</span><br></pre></td></tr></table></figure><p><strong>ReduceByKey</strong></p><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduceByKey</span></span>(func: (<span class="type">V</span>, <span class="type">V</span>) =&gt; <span class="type">V</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduceByKey</span></span>(func: (<span class="type">V</span>, <span class="type">V</span>) =&gt; <span class="type">V</span>, numPartitions: <span class="type">Int</span>): <span class="type">RDD</span>[(<span class="type">K</span>, <span class="type">V</span>)]</span><br></pre></td></tr></table></figure><p>groupByKey面向的是整个数据集<br>但是无论是groupByKey还是ReduceByKey都会对数据进行一次shuffle操作。</p><h2 id="groupByKey"><a href="#groupByKey" class="headerlink" title="groupByKey"></a>groupByKey</h2><p>groupByKey对一个分区的数据进行分组后就不会执行后续操作，要等待所有的分区数据全部到达后，才会进行后续操作。<br>在早期，shuffle是在内存中进行的，但是，很快发现，如果shuffle在内存中进行很容易出现内存溢出的情况。所以这个等待的情况应该被安排在磁盘中进行</p><h2 id="reduceByKey"><a href="#reduceByKey" class="headerlink" title="reduceByKey"></a>reduceByKey</h2><p>reduceByKey方法可以在shuffle之前进行分区内的聚合操作，称之为预聚和，这样，shuffle时落盘的数据量就减少了，提高了shuffle的性能</p>]]></content>
      
      
      <categories>
          
          <category> spark </category>
          
      </categories>
      
      
        <tags>
            
            <tag> spark </tag>
            
            <tag> 算子 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于sleep与wait的思考</title>
      <link href="/2020/05/11/java/%E5%85%B3%E4%BA%8Esleep%E4%B8%8Ewait%E7%9A%84%E6%80%9D%E8%80%83/"/>
      <url>/2020/05/11/java/%E5%85%B3%E4%BA%8Esleep%E4%B8%8Ewait%E7%9A%84%E6%80%9D%E8%80%83/</url>
      
        <content type="html"><![CDATA[<h1 id="关于sleep与wait的思考"><a href="#关于sleep与wait的思考" class="headerlink" title="关于sleep与wait的思考"></a>关于sleep与wait的思考</h1><h2 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h2><p>一说到sleep和wait的区别，最先想到是的<br>1.时间    sleep可以设置时间，wait<strong>一般不设置时间</strong>需要唤醒<br>2.对象锁    sleep不释放对象锁，而wait释放对象锁</p><h2 id="sleep和wait的核心区别"><a href="#sleep和wait的核心区别" class="headerlink" title="sleep和wait的核心区别"></a>sleep和wait的核心区别</h2><p><strong>sleep方法是静态的</strong><br>** wait是成员方法**</p><h3 id="sleep"><a href="#sleep" class="headerlink" title="sleep"></a>sleep</h3><p>关于sleep在java源码中只有简单的一句话</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">native</span> <span class="keyword">void</span> <span class="title">sleep</span><span class="params">(<span class="keyword">long</span> millis)</span> <span class="keyword">throws</span> InterruptedException</span>;</span><br></pre></td></tr></table></figure><p>从这句话看到sleep是静态的，<br><strong>静态方法和类型相关，和成员无关</strong><br>所以说，sleep方法属于谁调用就去休眠谁。<br>下面看这样一段代码</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JavaSleep</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">Thread t1 = <span class="keyword">new</span> Thread();</span><br><span class="line">t1.start;</span><br><span class="line">t1.sleep(<span class="number">1000</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这里我们发出一个疑问,在这段代码中休眠的是谁？<br>如果你能理解上面那句话，这里就会知道，上面的那段sleep与t1没有任何关系！<br>因为t1是一个对象，而sleep又与对象无关。所以sleep不可能让t1休眠。<br><strong>那么，这段代码中的sleep让谁休眠了？</strong><br>这个sleep是让当前正在执行的线程休眠，哪一个线程调用了sleep，休会休眠那个线程。<br><strong>所以，这个sleep会让main休眠</strong></p><h3 id="wait"><a href="#wait" class="headerlink" title="wait"></a>wait</h3><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">final</span> <span class="keyword">void</span> <span class="title">wait</span><span class="params">()</span> <span class="keyword">throws</span> InterruptedException </span>&#123;</span><br><span class="line">        wait(<span class="number">0</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>wait并没有用static修饰，所以wait是对象方法没有对象有关。</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">JavaWait</span> </span>&#123;</span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        Thread t2 = <span class="keyword">new</span> Thread();</span><br><span class="line">        t2.start;</span><br><span class="line">        t2.wait;</span><br></pre></td></tr></table></figure><p>所以这段代码中的wait会让t2去等待</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>关于java中的重写</title>
      <link href="/2020/04/23/java/%E5%85%B3%E4%BA%8Ejava%E4%B8%AD%E7%9A%84%E9%87%8D%E5%86%99/"/>
      <url>/2020/04/23/java/%E5%85%B3%E4%BA%8Ejava%E4%B8%AD%E7%9A%84%E9%87%8D%E5%86%99/</url>
      
        <content type="html"><![CDATA[<h1 id="关于java中的重写"><a href="#关于java中的重写" class="headerlink" title="关于java中的重写"></a>关于java中的重写</h1><p>首先贴一段简单的代码:看一下运行的结果</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.bryce.java;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Java05_overwrite</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">User2 user = <span class="keyword">new</span> User2();</span><br><span class="line">System.out.println(<span class="string">"user = "</span> + user.sum());</span><br><span class="line">Person user2 = <span class="keyword">new</span> User2();</span><br><span class="line">System.out.println(<span class="string">"user2 = "</span> + user2.sum());</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span></span>&#123;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">int</span> i = <span class="number">10</span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">sum</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">return</span> i + <span class="number">10</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User2</span> <span class="keyword">extends</span> <span class="title">Person</span></span>&#123;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">int</span> i = <span class="number">20</span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">sum</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">return</span> i + <span class="number">20</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>选中看答案<br>问题一：user = <font color=#fffff>40 </font><br>问题二：user2 = <font color=#fffff>40 </font></p><hr><p>如果两题都对了，那就再看看下面的</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.bryce.java;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Java05_overwrite</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">Person user3 = <span class="keyword">new</span> User2();</span><br><span class="line">System.out.println(<span class="string">"user3 = "</span> + user3.sum());</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span></span>&#123;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">int</span> i = <span class="number">10</span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">sum</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">return</span> i + <span class="number">10</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User2</span> <span class="keyword">extends</span> <span class="title">Person</span></span>&#123;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">int</span> i = <span class="number">20</span>;</span><br><span class="line"><span class="comment">//public int sum()&#123;</span></span><br><span class="line"><span class="comment">//return i + 20;</span></span><br><span class="line"><span class="comment">//&#125;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>问题三：user3 = <font color=#fffff>20 </font></p><p><strong>方法的重写：</strong><br>1.存在父子类关系，（子类重写父类的方法）<br>2.如果子类和父类都有相同的方法，那么遵循动态绑定机制<br><img src="https://img-blog.csdnimg.cn/20200525210516621.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JyeWNlX0xvc2tp,size_16,color_FFFFFF,t_70#pic_center" alt="在这里插入图片描述"></p><blockquote><p><strong>动态绑定机制</strong>：再程序的执行过程中，如果调用了对象的<strong>成员方法</strong>，那么会将对象的方法和对象实际的内存绑定。<strong>与属性无关</strong> 也就是说。</p></blockquote><p>Java05_overwrite再调用sum方法时，会先去寻找User中的sum方法，没有再去寻找Person中的方法。但是对于其中的属性，就不遵循动态绑定机制。也就是那个方法调用，就用那个类中的属性。</p><hr><p>By the way</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> cn.bryce.java;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Java05_overwrite</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">Person user4 = <span class="keyword">new</span> User2();</span><br><span class="line">System.out.println(<span class="string">"user4 = "</span> + user4.sum());</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Person</span></span>&#123;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">int</span> i = <span class="number">10</span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">sum</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">return</span> getI() + i;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getI</span> <span class="params">()</span></span>&#123; <span class="keyword">return</span> i; &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User2</span> <span class="keyword">extends</span> <span class="title">Person</span></span>&#123;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">int</span> i = <span class="number">20</span>;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getI</span> <span class="params">()</span></span>&#123; <span class="keyword">return</span> i; &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>问题四：user4 = <font color=#fffff>30 </font></p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>权限访问clone的思考</title>
      <link href="/2020/04/13/java/%E6%9D%83%E9%99%90%E8%AE%BF%E9%97%AEclone%E7%9A%84%E6%80%9D%E8%80%83/"/>
      <url>/2020/04/13/java/%E6%9D%83%E9%99%90%E8%AE%BF%E9%97%AEclone%E7%9A%84%E6%80%9D%E8%80%83/</url>
      
        <content type="html"><![CDATA[<p><strong>clone</strong>：这个方法估计都不陌生。object种的方法。</p><p><img src="https://img-blog.csdnimg.cn/20200525200317218.png#pic_center" alt="clone方法"><br>这个是object中的一个方法，我们都知道，任何类都会继承object这个类。<br>首先提出一个问题：</p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Java_Access</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">Object user = <span class="keyword">new</span> User();</span><br><span class="line">user.clone();</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">User</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这个clone的方法会报错吗？<br>如果你的答案时肯定的，且清晰的知道为什么，就可以愉快的跳过下面的内容。<br>如果你不知道会不会报错。那么就接着往下看。</p><p>答案：这个在编译的时候就会出错。</p><hr><p>分析：</p><p>这里就涉及到clone方法访问的权限：<br>protected:同类,同包或者子类<br>当我们访问一个方法的时候一共需要遵循两个原则：<br><strong>1.方法的提供者是否符合要求<br>2.方法的调用者是否符合要求</strong><br>首先抛出两个问题：</p><blockquote><p>1.clone方法的调用者是否是User<br>2.User所继承的父类Object是不是Java_Access的父类</p></blockquote><p>在这个方法中以clone为例：<br>①：方法的提供者：java.lang.Object<br>方法的调用者：xxx.xxx.<strong>Java_Access</strong><br>这里方法的调用者并不是User。</p><p><strong>而user.clone()的意思完整的来说：Java_Access的main方法中，创建了一个User对象，并且调用了user对象的clone方法。</strong><br>所以，clone并不符合同类或者同包的概念。</p><hr><p>②：这里clone方法的提供者Object和Java_Access并没有父子关系</p><p><img src="https://img-blog.csdnimg.cn/20200525203147371.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0JyeWNlX0xvc2tp,size_16,color_FFFFFF,t_70#pic_center" alt="clone的图片"><br>这里用一张图来表示。java_Access和User都有一个名叫Object的父类，但是这两个Object的之间并没有意点关系。所以，Java_Access并不能调用User父类Object中clone的方法。</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> clone </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hadoop Apache 2.7.2 安装教程</title>
      <link href="/2020/03/02/hadoop/Hadoop_Apache_2.7.2_%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/"/>
      <url>/2020/03/02/hadoop/Hadoop_Apache_2.7.2_%E5%AE%89%E8%A3%85%E6%95%99%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<h1 id="Hadoop-Apache-2-7-2-安装教程"><a href="#Hadoop-Apache-2-7-2-安装教程" class="headerlink" title="Hadoop Apache 2.7.2 安装教程"></a>Hadoop Apache 2.7.2 安装教程</h1><h2 id="1-JDK安装"><a href="#1-JDK安装" class="headerlink" title="1.JDK安装"></a>1.JDK安装</h2><p>&emsp;&emsp;hadoop的功能运行需要的JDK版本在1.7以上。所以先要查询JDK的版本是否在1.7以上。<br>1.查询方法：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">rpm -ga | grep java</span><br></pre></td></tr></table></figure><p>2.若不是，卸载，并安装jdk1.7以上版本</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">sudu rpm -e 软件包</span><br></pre></td></tr></table></figure><p><a href="https://blog.csdn.net/maobois/article/details/53414723" target="_blank" rel="noopener">如何对当前用户获取root权限。</a></p><blockquote><p><strong>jdk-8u144-linux-x64.tar安装包</strong><br>链接：<a href="https://pan.baidu.com/s/10-Vxjw3PgJrgOcXd4b14oA" target="_blank" rel="noopener">https://pan.baidu.com/s/10-Vxjw3PgJrgOcXd4b14oA</a><br>提取码：kqk6</p></blockquote><p>3.进入到JDK的软件包目录，解压JDK,</p><blockquote><p>笔者这里在/opt目录下创建了一个module目录，专门放各种软件</p></blockquote><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">tar -zxvf jdk-8u144-linux-x64.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure><p>4.配置JDK的环境变量<br>(1)获取JDK的路径：</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">pwd</span><br></pre></td></tr></table></figure><blockquote><p>/opt/module/jdk1.8.0_144</p></blockquote><p>(2)打开/etc/profile.d/env.sh.</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/profile.d/env.sh</span><br></pre></td></tr></table></figure><p>在env.sh中添加JDK路径</p><blockquote><p>#JAVA_HOME<br>export JAVA_HOME=/opt/module/jdk1.8.0_144<br>export PATH=$PATH:$JAVA_HOME/bin</p></blockquote><p>注：很多人这里配置的环境变量目录是/etc/profile的文件。两者的区别是/etc/profile.d目录下的文件在之后集群ssh到其他节点后会直接加载。避免了之后ssh到其他节点要重新刷新配置文件<br>(3) 刷新配置文件</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><p>(4)测试JDK是否安装成功</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">java -version</span><br></pre></td></tr></table></figure><h2 id="2-安装Hadoop"><a href="#2-安装Hadoop" class="headerlink" title="2.安装Hadoop"></a>2.安装Hadoop</h2><p>Hadoop下载地址：<a href="https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/" target="_blank" rel="noopener">https://archive.apache.org/dist/hadoop/common/hadoop-2.7.2/</a><br>1.将hadoop-2.7.2.tar.gz导入到linux<br>2.解压hadoop-2.7.2.tar.gz</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">tar -zxvf hadoop-2.7.2.tar.gz -C /opt/module/</span><br></pre></td></tr></table></figure><p>3.配置hadoop的环境变量<br>(1)获取hadoop的安装路径</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">pwd</span><br></pre></td></tr></table></figure><blockquote><p>/opt/module/hadoop-2.7.2</p></blockquote><p>(2)打开/etc/profile.d/env.sh文件</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">sudo vim /etc/profile.d/env.sh</span><br></pre></td></tr></table></figure><p>(3)在文件末尾加上Hadoop路径</p><blockquote><p>#HADOOP_HOME<br>export HADOOP_HOME=/opt/module/hadoop-2.7.2<br>export PATH=$PATH:$HADOOP_HOME/bin<br>export PATH=$PATH:$HADOOP_HOME/sbin</p></blockquote><p>(4)刷新配置文件让文件生效</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">source /etc/profile</span><br></pre></td></tr></table></figure><p>(5)测试Hadoop是否安装成功</p><figure class="highlight sql"><table><tr><td class="code"><pre><span class="line">hadoop version</span><br></pre></td></tr></table></figure><h2 id="3-完全分布式环境配置"><a href="#3-完全分布式环境配置" class="headerlink" title="3.完全分布式环境配置"></a>3.完全分布式环境配置</h2><p>安装前确认：</p><ol><li>确定客户机的台数(关闭防火墙，静态ip，主机名)，笔者为了测试简便，使用3台客户机，分别为hadoop111，hadoop112，hadoop113</li><li>安装JDK。参照上面</li><li>配置环境变量。参照上面</li><li>安装Hadoop。参照上面</li><li>配置集群</li><li>设置单点启动</li><li>配置ssh</li><li>群起测试集群</li></ol><p>(1)编写集群分发脚本<br>&emsp;&emsp;①在家目录下创建bin目录，并在bin目录下创建分发脚本xsync</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">ziyang</span>@<span class="type">hadoop111</span> ~]<span class="variable">$</span> mkdir bin</span><br><span class="line">[<span class="type">ziyang</span>@<span class="type">hadoop111</span> ~]<span class="variable">$</span> cd bin/</span><br><span class="line">[<span class="type">ziyang</span>@<span class="type">hadoop111</span> <span class="type">bin</span>]<span class="variable">$</span> vi xsync</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;②在脚本文件中编写分发代码</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment">#1 获取输入参数个数，如果没有参数，直接退出</span></span><br><span class="line">pcount=<span class="variable">$</span><span class="comment">#</span></span><br><span class="line"><span class="keyword">if</span> ((pcount==<span class="number">0</span>)); then</span><br><span class="line">echo no args;</span><br><span class="line"><span class="keyword">exit</span>;</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line"><span class="comment">#2 获取文件名称</span></span><br><span class="line">p1=<span class="variable">$1</span></span><br><span class="line">fname=`basename <span class="variable">$p1</span>`</span><br><span class="line">echo fname=<span class="variable">$fname</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#3 获取上级目录到绝对路径</span></span><br><span class="line">pdir=`cd <span class="literal">-P</span> <span class="variable">$</span>(dirname <span class="variable">$p1</span>); pwd`</span><br><span class="line">echo pdir=<span class="variable">$pdir</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#4 获取当前用户名称</span></span><br><span class="line">user=`whoami`</span><br><span class="line"></span><br><span class="line"><span class="comment">#5 循环</span></span><br><span class="line"><span class="keyword">for</span> host <span class="keyword">in</span> hadoop111 hadoop112 hadoop113</span><br><span class="line"><span class="keyword">do</span></span><br><span class="line">    echo ------------------- <span class="variable">$host</span> --------------</span><br><span class="line">    rsync <span class="literal">-av</span> <span class="variable">$pdir</span>/<span class="variable">$fname</span> <span class="variable">$user</span><span class="selector-tag">@</span><span class="variable">$host:</span><span class="variable">$pdir</span></span><br><span class="line">done</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;③修改权限</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">ziyang</span>@<span class="type">hadoop111</span> <span class="type">bin</span>]<span class="variable">$</span> chmod <span class="number">777</span> xsync</span><br></pre></td></tr></table></figure><p>&emsp;&emsp;④测试脚本</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">ziyang</span>@<span class="type">hadoop111</span> <span class="type">bin</span>]<span class="variable">$</span> xsync xsync</span><br></pre></td></tr></table></figure><p>（2）<a href="https://www.linuxidc.com/Linux/2017-07/145450.htm" target="_blank" rel="noopener">配置SSH无秘钥登录</a><br>简单叙述：进入家目录的.ssh目录<br>①生成公钥和私钥：</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">ziyang</span>@<span class="type">hadoop111</span> <span class="type">.ssh</span>]<span class="variable">$</span> ssh<span class="literal">-keygen</span> <span class="literal">-t</span> rsa</span><br></pre></td></tr></table></figure><blockquote><p>然后敲（三个回车），就会生成两个文件id_rsa（私钥）、id_rsa.pub（公钥）</p></blockquote><p>②将公钥拷贝到要免密登录的目标机器上<br>[ziyang@hadoop111 .ssh]$ ssh-copy-id hadoop111<br>[ziyang@hadoop111 .ssh]$ ssh-copy-id hadoop112<br>[ziyang@hadoop111 .ssh]$ ssh-copy-id hadoop113<br><font color=red><br>注意：<br>还需要在hadoop112上采用atguigu账号配置一下无密登录到hadoop111、hadoop112、hadoop113服务器上。<br>hadoop113同理<br></font><br>(3)集群规划<br>①在搭集群前，首先要对集群有一个详细的规划。<br>注意：NameNode和SecondaryNameNode还有ResourceManager不要安装在同一台服务器<br>所以对于3台机器的集群规划<br>|| hadoop111 | hadoop112 | hadoop113 |<br>|–|–|–|–|<br>| HDFS | NameNode、DateNode |DateNode|SecondaryNameNode、DateNode|<br>| YARN | NodeManager |ResourceManager、NodeManager|NodeManager|<br>②核心文件配置<br>核心文件的配置一共有<br>core-site.xml<br>hdfs-site.xml<br>yarn-site.xml<br>mapred-site.xml</p><p>hadoop-env.sh<br>yarn-env.sh<br>mapred-env.sh</p><p>slaves<br>1)进入hadoop的配置目录</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">ziyang</span>@<span class="type">hadoop111</span> ~]<span class="variable">$</span> cd /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/etc/hadoop/</span><br></pre></td></tr></table></figure><p>2）配置核心配置文件core-site.xml<br>在该文件中编写如下配置</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;!-- 指定HDFS中NameNode的地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;hdfs://hadoop102:<span class="number">9000</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定Hadoop运行时产生文件的存储目录 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">&lt;value&gt;/opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/<span class="keyword">data</span>/tmp&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>3）配置HDFS配置文件hdfs-site.xml与hadoop-env.sh<br>3.1配置hdfs-site.xml<br>在该文件中编写如下配置</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">&lt;value&gt;<span class="number">3</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定Hadoop辅助名称节点主机配置 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">      &lt;name&gt;dfs.namenode.secondary.http<span class="literal">-address</span>&lt;/name&gt;</span><br><span class="line">      &lt;value&gt;hadoop113:<span class="number">50090</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>3.2配置hadoop-env.sh</p><blockquote><p>仔细找，在如下的信息下面<br> <code># The java implementation to use.</code><br>在下一行去掉注释，加上JDK的路径</p></blockquote><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.<span class="number">8.0</span>_144</span><br></pre></td></tr></table></figure><p>4）配置Yarn配置文件yarn-site.xml与yarn-env.sh<br>4.1配置yarn-site.xml文件<br>在该文件中编写如下配置</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;!-- Reducer获取数据的方式 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.nodemanager.aux<span class="literal">-services</span>&lt;/name&gt;</span><br><span class="line">&lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 指定YARN的ResourceManager的地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;</span><br><span class="line">&lt;value&gt;hadoop112&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 日志聚集功能使能 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.log<span class="literal">-aggregation</span><span class="literal">-enable</span>&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 日志保留时间设置<span class="number">7</span>天 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.log<span class="literal">-aggregation</span>.retain<span class="literal">-seconds</span>&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;<span class="number">604800</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>4.2配置yarn-env.sh文件</p><blockquote><p>仔细找，在如下信息下面<br> <code># some Java parameters</code><br> 在下一行去掉注释，加上JDK路径</p></blockquote><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">export JAVA_HOME=/opt/module/jdk1.<span class="number">8.0</span>_144</span><br></pre></td></tr></table></figure><p>5）配置MapReduce配置文件中mapred-site.xml与mapred-env.sh<br>5.1配置mapred-site.xml</p><blockquote><p>将mapred-site.xml的后缀名去掉<br>mv mapred-site.xml.template mapred-site.xml</p></blockquote><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;!-- 指定MR运行在Yarn上 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">&lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 历史服务器端地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hadoop102:<span class="number">10020</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;!-- 历史服务器web端地址 --&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hadoop102:<span class="number">19888</span>&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure><p>5.2配置mapred-env.sh</p><blockquote><p>还是一样配置JDK路径<br>export JAVA_HOME=/opt/module/jdk1.8.0_144</p></blockquote><p>6）配置salaves<br>在文件中加入客户端的名字</p><blockquote><p>hadoop111<br>hadoop112<br>hadoop113</p></blockquote><font color=red>注意：该文件中添加的内容结尾不允许有空格，文件中不允许有空行。</font><p>(4) 分别在hadoop112、hadoop113的/opt目录下创建module文件夹，并修改所有者和所有者组为你的用户名</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">ziyang</span>@<span class="type">hadoop112</span> <span class="type">opt</span>]<span class="variable">$</span> sudo mkdir module</span><br><span class="line">[<span class="type">ziyang</span>@<span class="type">hadoop112</span> <span class="type">opt</span>]<span class="variable">$</span> sudo chown atguigu:atguigu module/</span><br><span class="line">[<span class="type">ziyang</span>@<span class="type">hadoop113</span> <span class="type">opt</span>]<span class="variable">$</span> sudo mkdir module</span><br><span class="line">[<span class="type">ziyang</span>@<span class="type">hadoop113</span> <span class="type">opt</span>]<span class="variable">$</span> sudo chown atguigu:atguigu module/</span><br></pre></td></tr></table></figure><p>分发JDK文件与Hadoop文件</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">xsync /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/</span><br><span class="line">xsync jdk1.<span class="number">8.0</span>_144/</span><br></pre></td></tr></table></figure><p>在其他的客户端集群配置好配置文件<br>(5)群启集群<br>1）如果集群是第一次启动，需要格式化NameNode（注意格式化之前，一定要先停止上次启动的所有namenode和datanode进程，然后再删除data和log数据）</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">ziyang</span>@<span class="type">hadoop111</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> bin/hdfs namenode <span class="literal">-format</span></span><br></pre></td></tr></table></figure><p>2）启动HDFS</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">ziyang</span>@<span class="type">hadoop111</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> sbin/<span class="built_in">start-dsf</span>.sh</span><br></pre></td></tr></table></figure><p>3)启动Yarn<br><font color=red><br>因为yarn配置在hadoop112所以要去hadoop112启动<br></font></p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">ziyang</span>@<span class="type">hadoop112</span> <span class="type">hadoop</span>-<span class="number">2.7</span><span class="type">.2</span>]<span class="variable">$</span> sbin/<span class="built_in">start-yarn</span>.sh</span><br></pre></td></tr></table></figure><h2 id="4-支持LZO压缩配置"><a href="#4-支持LZO压缩配置" class="headerlink" title="4.支持LZO压缩配置"></a>4.支持LZO压缩配置</h2><p>(1）hadoop本身并不支持lzo压缩，故需要使用twitter提供的hadoop-lzo开源组件。hadoop-lzo需依赖hadoop和lzo进行编译。<br>以下是编译好的Lzo压缩文件</p><blockquote><p>链接：<a href="https://pan.baidu.com/s/1b46cClcMlruI3FYViM_eVw" target="_blank" rel="noopener">https://pan.baidu.com/s/1b46cClcMlruI3FYViM_eVw</a><br>提取码：nkzh</p></blockquote><p>(2)直接将编译好的jar包放入hadoop-2.7.2/share/hadoop/common/<br>并同步到hadoop112，hadoop113</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">ziyang</span>@<span class="type">hadoop112</span> <span class="type">common</span>]<span class="variable">$</span> xsync hadoop<span class="literal">-lzo</span><span class="literal">-0</span>.<span class="number">4.20</span>.jar</span><br></pre></td></tr></table></figure><p>(3)在core-site.xml中增加支持LZO压缩</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line">&lt;property&gt;</span><br><span class="line">&lt;name&gt;io.compression.codecs&lt;/name&gt;</span><br><span class="line">&lt;value&gt;</span><br><span class="line">org.apache.hadoop.io.compress.GzipCodec,</span><br><span class="line">org.apache.hadoop.io.compress.DefaultCodec,</span><br><span class="line">org.apache.hadoop.io.compress.BZip2Codec,</span><br><span class="line">org.apache.hadoop.io.compress.SnappyCodec,</span><br><span class="line">com.hadoop.compression.lzo.LzoCodec,</span><br><span class="line">com.hadoop.compression.lzo.LzopCodec</span><br><span class="line">&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;io.compression.codec.lzo<span class="class">.<span class="keyword">class</span>&lt;/<span class="title">name</span>&gt;</span></span><br><span class="line"><span class="class">    &lt;<span class="title">value</span>&gt;<span class="title">com</span>.<span class="title">hadoop</span>.<span class="title">compression</span>.<span class="title">lzo</span>.<span class="title">LzoCodec</span>&lt;/<span class="title">value</span>&gt;</span></span><br><span class="line"><span class="class">&lt;/<span class="title">property</span>&gt;</span></span><br><span class="line"><span class="class">&lt;/<span class="title">configuration</span>&gt;</span></span><br></pre></td></tr></table></figure><p>同步到hadoop112，hadoop113</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">ziyang</span>@<span class="type">hadoop112</span> <span class="type">hadoop</span>]<span class="variable">$</span> xsync core<span class="literal">-site</span>.xml</span><br></pre></td></tr></table></figure><p>(4)启动集群<br><font color=red><br>LZO压缩文件可切片性的特性依赖于启索引，所以，在分析LZO文件的时候我们都要手动为其创建索引<br></font></p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">[<span class="type">ziyang</span>@<span class="type">hadoop112</span> <span class="type">module</span>]<span class="variable">$</span> hadoop jar /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/share/hadoop/common/hadoop<span class="literal">-lzo</span><span class="literal">-0</span>.<span class="number">4.20</span>.jar  com.hadoop.compression.lzo.DistributedLzoIndexer 文件在HDFS上的路径</span><br></pre></td></tr></table></figure><h2 id="5-HDFS扩容配置"><a href="#5-HDFS扩容配置" class="headerlink" title="5.HDFS扩容配置"></a>5.HDFS扩容配置</h2><p>有需要留言更新</p><h2 id="6-HDFS基准测试"><a href="#6-HDFS基准测试" class="headerlink" title="6.HDFS基准测试"></a>6.HDFS基准测试</h2><p>此内容用于测试HDFS的读写性能，<strong>PC端请量力而行</strong>可以跳过<br>(1)测试HDFS写的性能<br>&emsp;测试内容：向HDFS集群写100个128M的文件</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">hadoop jar /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/share/hadoop/mapreduce/hadoop<span class="literal">-mapreduce</span><span class="literal">-client</span><span class="literal">-jobclient</span><span class="literal">-2</span>.<span class="number">7.2</span><span class="literal">-tests</span>.jar TestDFSIO <span class="literal">-write</span> <span class="literal">-nrFiles</span> <span class="number">100</span> <span class="literal">-fileSize</span> <span class="number">128</span>MB</span><br></pre></td></tr></table></figure><p>(2)测试HDFS读的性能<br>emsp;测试内容：向HDFS集群读100个128M的文件</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">hadoop jar /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/share/hadoop/mapreduce/hadoop<span class="literal">-mapreduce</span><span class="literal">-client</span><span class="literal">-jobclient</span><span class="literal">-2</span>.<span class="number">7.2</span><span class="literal">-tests</span>.jar TestDFSIO <span class="literal">-read</span> <span class="literal">-nrFiles</span> <span class="number">100</span> <span class="literal">-fileSize</span> <span class="number">128</span>MB</span><br></pre></td></tr></table></figure><p>(3)删除测试生成数据</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">hadoop jar /opt/module/hadoop<span class="literal">-2</span>.<span class="number">7.2</span>/share/hadoop/mapreduce/hadoop<span class="literal">-mapreduce</span><span class="literal">-client</span><span class="literal">-jobclient</span><span class="literal">-2</span>.<span class="number">7.2</span><span class="literal">-tests</span>.jar TestDFSIO <span class="literal">-clean</span></span><br></pre></td></tr></table></figure><h2 id="7-Hadoop参数调优"><a href="#7-Hadoop参数调优" class="headerlink" title="7.Hadoop参数调优"></a>7.Hadoop参数调优</h2><p>有需要留言更新</p>]]></content>
      
      
      <categories>
          
          <category> hadoop </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 大数据 </tag>
            
            <tag> hadoop </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>shell脚本执行jps时：-bash: jps: command not found</title>
      <link href="/2020/02/15/linux/command_not_found/"/>
      <url>/2020/02/15/linux/command_not_found/</url>
      
        <content type="html"><![CDATA[<p>我构建了hadoop集群。我们一定会写一个shell脚本去每一个节点上去jps，查看每个节点的进程情况。</p><p>原先以为shell很简单：</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line"><span class="comment">#!/bin/bash</span></span><br><span class="line"><span class="comment">#查看每个节点运行情况</span></span><br><span class="line"><span class="keyword">for</span>((host=<span class="number">101</span>;host&lt;<span class="number">108</span>;host++));<span class="keyword">do</span></span><br><span class="line">echo ----------<span class="literal">-hadoop</span><span class="variable">$host</span>-------------</span><br><span class="line">ssh hadoop<span class="variable">$host</span> <span class="string">"jps"</span></span><br><span class="line">done</span><br></pre></td></tr></table></figure><p><strong>这里默认服务器节点的名字是hadoop101-hadoop107</strong><br><strong>默认已经配置了ssh_key的公钥和私钥</strong><br>看是运行这段程序的时候会弹出一个错误：</p><h2 id="bash-jps-command-not-found"><a href="#bash-jps-command-not-found" class="headerlink" title="-bash: jps: command not found"></a>-bash: jps: command not found</h2><p>错误原因：<br>在shell脚本写的ssh到其他节点的时候默认是不加载配置文件的。linux并不能去找到java中jps的命令。</p><ul><li><strong>解决方案一</strong>：在ssh到其他节点的时候source 一下配置文件。<br>具体操作为：ssh hadoop$host “source /etc/profile;jps”</li><li><strong>解决方案二</strong>：在ssh到其他节点的时候输入jps命令下的绝对路径。<br>在笔者的linux的jdk的绝对路径为：/opt/module/jdk1.8.0_144/bin这个目录下就有jps的命令。<br>具体操作为：ssh hadoop$host “/opt/module/jdk1.8.0_144/bin/jps”<ul><li><strong>解决方案三</strong>：在当前用户的家目录中输入命令<strong>ll -a</strong>会显示隐藏文件，修改配置文件.bashrc。<br>.bashrc 是当你登入shell时执行<br>在其中添加JDK的环境变量</li><li><strong>解决方案四</strong>：在/etc/profile.d目录下创建一个以sh结尾的文件。将profile配的环境变量拷贝到这个文件目录下</li></ul></li></ul><p>运行结果：</p><figure class="highlight powershell"><table><tr><td class="code"><pre><span class="line">----------<span class="literal">-hadoop101</span>-------------</span><br><span class="line"><span class="number">10720</span> DataNode</span><br><span class="line"><span class="number">10993</span> NodeManager</span><br><span class="line"><span class="number">10573</span> NameNode</span><br><span class="line"><span class="number">19663</span> Jps</span><br><span class="line">----------<span class="literal">-hadoop102</span>-------------</span><br><span class="line"><span class="number">37744</span> Jps</span><br><span class="line"><span class="number">31282</span> NodeManager</span><br><span class="line"><span class="number">31154</span> ResourceManager</span><br><span class="line"><span class="number">31036</span> DataNode</span><br><span class="line">----------<span class="literal">-hadoop103</span>-------------</span><br><span class="line"><span class="number">30725</span> NodeManager</span><br><span class="line"><span class="number">30620</span> SecondaryNameNode</span><br><span class="line"><span class="number">30511</span> DataNode</span><br><span class="line"><span class="number">41135</span> Jps</span><br><span class="line">----------<span class="literal">-hadoop104</span>-------------</span><br><span class="line"><span class="number">30995</span> DataNode</span><br><span class="line"><span class="number">31109</span> NodeManager</span><br><span class="line"><span class="number">37483</span> Jps</span><br><span class="line">----------<span class="literal">-hadoop105</span>-------------</span><br><span class="line"><span class="number">30882</span> NodeManager</span><br><span class="line"><span class="number">30766</span> DataNode</span><br><span class="line"><span class="number">37358</span> Jps</span><br><span class="line">----------<span class="literal">-hadoop106</span>-------------</span><br><span class="line"><span class="number">8816</span> Jps</span><br><span class="line"><span class="number">2592</span> NodeManager</span><br><span class="line"><span class="number">2477</span> DataNode</span><br><span class="line">----------<span class="literal">-hadoop107</span>-------------</span><br><span class="line"><span class="number">37445</span> Jps</span><br><span class="line"><span class="number">31035</span> DataNode</span><br><span class="line"><span class="number">31151</span> NodeManager</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
          <category> shell </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> shell </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>JAVA几道基础常见的面试题</title>
      <link href="/2020/02/13/java/JAVA%E5%87%A0%E9%81%93%E5%B8%B8%E8%A7%81%E7%9A%84%E5%9F%BA%E7%A1%80%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
      <url>/2020/02/13/java/JAVA%E5%87%A0%E9%81%93%E5%B8%B8%E8%A7%81%E7%9A%84%E5%9F%BA%E7%A1%80%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h1 id="JAVA几道常见的面试题"><a href="#JAVA几道常见的面试题" class="headerlink" title="JAVA几道常见的面试题"></a>JAVA几道常见的面试题</h1><h2 id="Java自带哪几种线程池？"><a href="#Java自带哪几种线程池？" class="headerlink" title="Java自带哪几种线程池？"></a>Java自带哪几种线程池？</h2><ol><li>newCachedThreadPool<br>创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。这种类型的线程池特点是：<br>工作线程的创建数量几乎没有限制（其实也有限制的，数目为Interger. MAX_VALUE）, 这样可灵活的往线程池中添加线程。<br>如果长时间没有往线程池中提交任务，即如果工作线程空闲了指定的时间（默认为1分钟），则该工作线程将自动终止。终止后，如果你又提交了新的任务，则线程池重新创建一个工作线程。<br>在使用CachedThreadPool时，一定要注意控制任务的数量，否则，由于大量线程同时运行，很有会造成系统瘫痪。</li><li>newFixedThreadPool<br>创建一个指定工作线程数量的线程池。每当提交一个任务就创建一个工作线程，如果工作线程数量达到线程池初始的最大数，则将提交的任务存入到池队列中。FixedThreadPool是一个典型且优秀的线程池，它具有线程池提高程序效率和节省创建线程时所耗的开销的优点。但是，在线程池空闲时，即线程池中没有可运行任务时，它不会释放工作线程，还会占用一定的系统资源。</li><li>newSingleThreadExecutor<br>创建一个单线程化的Executor，即只创建唯一的工作者线程来执行任务，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序（FIFO, LIFO, 优先级）执行。如果这个线程异常结束，会有另一个取代它，保证顺序执行。单工作线程最大的特点是可保证顺序地执行各个任务，并且在任意给定的时间不会有多个线程是活动的。</li><li>newScheduleThreadPool<br>创建一个定长的线程池，而且支持定时的以及周期性的任务执行，支持定时及周期性任务执行。延迟3秒执行。</li></ol><h2 id="HashMap和HashTable区别"><a href="#HashMap和HashTable区别" class="headerlink" title="HashMap和HashTable区别"></a>HashMap和HashTable区别</h2><ol><li>线程安全性不同<br>HashMap是线程不安全的，HashTable是线程安全的，其中的方法是Synchronize的，在多线程并发的情况下，可以直接使用HashTabl，但是使用HashMap时必须自己增加同步处理。</li><li>是否提供contains方法<br>HashMap只有containsValue和containsKey方法；HashTable有contains、containsKey和containsValue三个方法，其中contains和containsValue方法功能相同。</li><li>key和value是否允许null值<br>Hashtable中，key和value都不允许出现null值。HashMap中，null可以作为键，这样的键只有一个；可以有一个或多个键所对应的值为null。</li><li>数组初始化和扩容机制<br>HashTable在不指定容量的情况下的默认容量为11，而HashMap为16，Hashtable不要求底层数组的容量一定要为2的整数次幂，而HashMap则要求一定为2的整数次幂。<br>Hashtable扩容时，将容量变为原来的2倍加1，而HashMap扩容时，将容量变为原来的2倍。</li></ol><h2 id="TreeSet和HashSet区别"><a href="#TreeSet和HashSet区别" class="headerlink" title="TreeSet和HashSet区别"></a>TreeSet和HashSet区别</h2><p>HashSet是采用hash表来实现的。其中的元素没有按顺序排列，add()、remove()以及contains()等方法都是复杂度为O(1)的方法。<br>TreeSet是采用树结构实现（红黑树算法）。元素是按顺序进行排列，但是add()、remove()以及contains()等方法都是复杂度为O(log (n))的方法。它还提供了一些方法来处理排序的set，如first()，last()，headSet()，tailSet()等等。</p><h2 id="String-buffer和String-build区别"><a href="#String-buffer和String-build区别" class="headerlink" title="String buffer和String build区别"></a>String buffer和String build区别</h2><ol><li>StringBuffer与StringBuilder中的方法和功能完全是等价的。</li><li>只是StringBuffer中的方法大都采用了 synchronized 关键字进行修饰，因此是线程安全的，而StringBuilder没有这个修饰，可以被认为是线程不安全的。 </li><li>在单线程程序下，StringBuilder效率更快，因为它不需要加锁，不具备多线程安全而StringBuffer则每次都需要判断锁，效率相对更低</li></ol><h2 id="Final、Finally、Finalize"><a href="#Final、Finally、Finalize" class="headerlink" title="Final、Finally、Finalize"></a>Final、Finally、Finalize</h2><p>final：修饰符（关键字）有三种用法：修饰类、变量和方法。修饰类时，意味着它不能再派生出新的子类，即不能被继承，因此它和abstract是反义词。修饰变量时，该变量使用中不被改变，必须在声明时给定初值，在引用中只能读取不可修改，即为常量。修饰方法时，也同样只能使用，不能在子类中被重写。<br>finally：通常放在try…catch的后面构造最终执行代码块，这就意味着程序无论正常执行还是发生异常，这里的代码只要JVM不关闭都能执行，可以将释放外部资源的代码写在finally块中。<br>finalize：Object类中定义的方法，Java中允许使用finalize() 方法在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。这个方法是由垃圾收集器在销毁对象时调用的，通过重写finalize() 方法可以整理系统资源或者执行其他清理工作。</p>]]></content>
      
      
      <categories>
          
          <category> java </category>
          
          <category> 面试题 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> java </tag>
            
            <tag> 面试题 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>用数组和链表分别实现栈</title>
      <link href="/2019/12/10/java/DataStructures/%E7%94%A8%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E5%88%86%E5%88%AB%E5%AE%9E%E7%8E%B0%E6%A0%88/"/>
      <url>/2019/12/10/java/DataStructures/%E7%94%A8%E6%95%B0%E7%BB%84%E5%92%8C%E9%93%BE%E8%A1%A8%E5%88%86%E5%88%AB%E5%AE%9E%E7%8E%B0%E6%A0%88/</url>
      
        <content type="html"><![CDATA[<h1 id="用数组和链表分别实现栈"><a href="#用数组和链表分别实现栈" class="headerlink" title="用数组和链表分别实现栈"></a>用数组和链表分别实现栈</h1><h2 id="数组版"><a href="#数组版" class="headerlink" title="数组版"></a>数组版</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">ArrayStrakDemo</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line"><span class="comment">//TODO 用数组模拟栈的实现</span></span><br><span class="line">ArrayStark stark = <span class="keyword">new</span> ArrayStark(<span class="number">4</span>);</span><br><span class="line">String key;</span><br><span class="line"><span class="keyword">boolean</span> loop = <span class="keyword">true</span>;</span><br><span class="line">Scanner scanner = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(loop)&#123;</span><br><span class="line">System.out.println(<span class="string">"show"</span>);</span><br><span class="line">System.out.println(<span class="string">"exit"</span>);</span><br><span class="line">System.out.println(<span class="string">"push"</span>);</span><br><span class="line">System.out.println(<span class="string">"pop"</span>);</span><br><span class="line">System.out.println(<span class="string">"Enter yor choose"</span>);</span><br><span class="line">key = scanner.next();</span><br><span class="line"><span class="keyword">switch</span> (key)&#123;</span><br><span class="line"><span class="keyword">case</span> <span class="string">"show"</span>:</span><br><span class="line">stark.list();</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="string">"push"</span>:</span><br><span class="line">System.out.println(<span class="string">"Enter the number"</span>);</span><br><span class="line">stark.push(scanner.nextInt());</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="string">"pop"</span>:</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="keyword">int</span> pop = stark.pop();</span><br><span class="line">System.out.printf(<span class="string">"The number is %d\n"</span>,pop);</span><br><span class="line">&#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">System.out.println(e.getMessage());</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="string">"exit"</span>:</span><br><span class="line">scanner.close();</span><br><span class="line">loop = <span class="keyword">false</span>;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(<span class="string">"程序退出"</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//表示栈结构</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ArrayStark</span></span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> maxSize; <span class="comment">//栈的大小</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span>[] stark;<span class="comment">//数组，模拟栈，数据存在数组中</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> top = -<span class="number">1</span>;<span class="comment">//表示栈顶，初始值为-1表示没有数据</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//构造器</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">ArrayStark</span><span class="params">(<span class="keyword">int</span> maxSize)</span></span>&#123;</span><br><span class="line"><span class="keyword">this</span>.maxSize = maxSize;</span><br><span class="line">stark = <span class="keyword">new</span> <span class="keyword">int</span>[<span class="keyword">this</span>.maxSize];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//栈满</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isFull</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">return</span> top == maxSize-<span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//栈空</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isEmpty</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">return</span> top == -<span class="number">1</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//入栈</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">push</span><span class="params">(<span class="keyword">int</span> value)</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(isFull())&#123;</span><br><span class="line">System.out.println(<span class="string">"栈满"</span>);</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line">top++;</span><br><span class="line">stark[top] = value;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//出栈</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">pop</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(isEmpty())&#123;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"空的"</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> stark[top--];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//显示栈的情况,从栈顶往下遍历</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">list</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(isEmpty())&#123;</span><br><span class="line">System.out.println(<span class="string">"没有数据"</span>);</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span>(<span class="keyword">int</span> i = top;i &gt;= <span class="number">0</span>; i--)&#123;</span><br><span class="line">System.out.printf(<span class="string">"stark[%d]=%d\n"</span>,i,stark[i]);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="链表版"><a href="#链表版" class="headerlink" title="链表版"></a>链表版</h2><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">LinkedStrakDemo</span> </span>&#123;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</span><br><span class="line">LinkedStark stark = <span class="keyword">new</span> LinkedStark(<span class="number">4</span>);</span><br><span class="line"><span class="keyword">boolean</span> loop = <span class="keyword">true</span>;</span><br><span class="line">String key;</span><br><span class="line">Scanner scanner = <span class="keyword">new</span> Scanner(System.in);</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span>(loop)&#123;</span><br><span class="line">System.out.println(<span class="string">"show"</span>);</span><br><span class="line">System.out.println(<span class="string">"exit"</span>);</span><br><span class="line">System.out.println(<span class="string">"push"</span>);</span><br><span class="line">System.out.println(<span class="string">"pop"</span>);</span><br><span class="line">System.out.println(<span class="string">"Enter yor choose"</span>);</span><br><span class="line">key = scanner.next();</span><br><span class="line"><span class="keyword">switch</span> (key)&#123;</span><br><span class="line"><span class="keyword">case</span> <span class="string">"show"</span>:</span><br><span class="line">stark.list();</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="string">"push"</span>:</span><br><span class="line">System.out.println(<span class="string">"Enter the number"</span>);</span><br><span class="line">stark.push(scanner.nextInt());</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="string">"pop"</span>:</span><br><span class="line"><span class="keyword">try</span> &#123;</span><br><span class="line"><span class="keyword">int</span> pop = stark.pop();</span><br><span class="line">System.out.printf(<span class="string">"The number is %d\n"</span>,pop);</span><br><span class="line">&#125;<span class="keyword">catch</span> (Exception e)&#123;</span><br><span class="line">System.out.println(e.getMessage());</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> <span class="string">"exit"</span>:</span><br><span class="line">scanner.close();</span><br><span class="line">loop = <span class="keyword">false</span>;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">System.out.println(<span class="string">"程序退出"</span>);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Node</span></span>&#123;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">int</span> num;</span><br><span class="line"><span class="keyword">public</span> Node next;</span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">Node</span><span class="params">(<span class="keyword">int</span> num)</span></span>&#123;</span><br><span class="line"><span class="keyword">this</span>.num = num;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">LinkedStark</span></span>&#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">int</span> maxSize; <span class="comment">//栈的容量</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">int</span> nums;   <span class="comment">//栈当前的大小</span></span><br><span class="line"><span class="keyword">private</span> Node top;<span class="comment">//表示栈顶的元素</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="title">LinkedStark</span><span class="params">(<span class="keyword">int</span> maxSize)</span></span>&#123;</span><br><span class="line"><span class="keyword">this</span>.maxSize = maxSize;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//栈满</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isPull</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">return</span> nums == maxSize;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//栈空</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">boolean</span> <span class="title">isEmpty</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">return</span> nums == <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//添加元素</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">push</span><span class="params">(<span class="keyword">int</span> n)</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(isPull())&#123;</span><br><span class="line">System.out.println(<span class="string">"栈满"</span>);</span><br><span class="line">&#125;<span class="keyword">else</span> &#123;</span><br><span class="line"><span class="comment">//将栈顶的旧元素节点保存</span></span><br><span class="line">Node oldNode = top;</span><br><span class="line"><span class="comment">//替换新的栈顶的元素</span></span><br><span class="line">top = <span class="keyword">new</span> Node(n);</span><br><span class="line">top.next = oldNode;</span><br><span class="line">nums++;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//缩减元素</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">pop</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(isEmpty())&#123;</span><br><span class="line"><span class="keyword">throw</span> <span class="keyword">new</span> RuntimeException(<span class="string">"栈空"</span>);</span><br><span class="line">&#125;<span class="keyword">else</span> &#123;</span><br><span class="line"><span class="comment">//取出当前栈顶元素的值</span></span><br><span class="line"><span class="keyword">int</span> value = top.num;</span><br><span class="line"><span class="comment">//舍弃当前栈顶的节点</span></span><br><span class="line">top = top.next;</span><br><span class="line">nums--;</span><br><span class="line"><span class="keyword">return</span> value;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//显示栈的情况</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">list</span><span class="params">()</span></span>&#123;</span><br><span class="line"><span class="keyword">if</span>(isEmpty())&#123;</span><br><span class="line">System.out.println(<span class="string">"栈空"</span>);</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">for</span>(Node node = top;node.next != <span class="keyword">null</span>; node = node.next)&#123;</span><br><span class="line">System.out.println(node.num);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> 数据结构 </category>
          
          <category> 栈 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据结构 </tag>
            
            <tag> 栈 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
